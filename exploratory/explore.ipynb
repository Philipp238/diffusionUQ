{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import pathlib\n",
    "import logging\n",
    "import argparse\n",
    "import configparser\n",
    "import ast\n",
    "import shutil\n",
    "from data.datasets import DarcyFlowDataset, KSDataset, ERA5Dataset, SSWEDataset\n",
    "from models import FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parameters = {\n",
    "    'dataset_name': 'KS',\n",
    "    'downscaling_factor': 1,\n",
    "    'temporal_downscaling': 2,\n",
    "    'pred_horizon': 5,\n",
    "    't_start': 0,\n",
    "    'init_steps': 5\n",
    "}\n",
    "\n",
    "training_parameters = {\n",
    "    'batch_size': 32,\n",
    "    'model': 'FNO',\n",
    "    'uncertainty_quantification': 'dropout',\n",
    "    'n_modes': (10, 12),\n",
    "    'hidden_channels': 20,\n",
    "    'dropout': 0.05,\n",
    "    'lifting_channels': 128,\n",
    "    'fourier_dropout': None,\n",
    "    'projection_channels': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"data/{data_parameters[\"dataset_name\"]}/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_parameters['dataset_name'] == 'DarcyFlow':\n",
    "    train_data = DarcyFlowDataset(data_dir, test = False, downscaling_factor=int(data_parameters['downscaling_factor']))\n",
    "    train_data_full_res = DarcyFlowDataset(data_dir, test = False)\n",
    "    test_data = DarcyFlowDataset(data_dir, test = True)            \n",
    "elif data_parameters[\"dataset_name\"] == \"KS\":\n",
    "    downscaling_factor = int(data_parameters['downscaling_factor'])\n",
    "    temporal_downscaling_factor = int(data_parameters['temporal_downscaling'])\n",
    "    pred_horizon = data_parameters['pred_horizon']\n",
    "    t_start = data_parameters['t_start']\n",
    "    init_steps = data_parameters['init_steps']\n",
    "\n",
    "    assert 300 > temporal_downscaling_factor * (pred_horizon + t_start + init_steps)\n",
    "\n",
    "    train_data = KSDataset(data_dir, test = False, downscaling_factor=downscaling_factor, mode = \"autoregressive\",\n",
    "                pred_horizon=pred_horizon, t_start=t_start, init_steps=init_steps,\n",
    "                temporal_downscaling_factor=temporal_downscaling_factor)\n",
    "    test_data = KSDataset(data_dir, test = True, mode = \"autoregressive\",\n",
    "                pred_horizon=pred_horizon, t_start=t_start, init_steps=init_steps,\n",
    "                temporal_downscaling_factor=temporal_downscaling_factor)\n",
    "    \n",
    "elif data_parameters[\"dataset_name\"] == \"era5\":\n",
    "    data_dir = f\"data/{data_parameters['dataset_name']}/\"\n",
    "    pred_horizon = data_parameters['pred_horizon']\n",
    "    init_steps = data_parameters['init_steps']\n",
    "    train_data = ERA5Dataset(data_dir, var = \"train\", init_steps = init_steps, prediction_steps = pred_horizon)\n",
    "    val_data = ERA5Dataset(data_dir, var = \"val\", init_steps = init_steps, prediction_steps = pred_horizon)\n",
    "    test_data = ERA5Dataset(data_dir, var = \"test\", init_steps = init_steps, prediction_steps = pred_horizon)\n",
    "\n",
    "elif data_parameters[\"dataset_name\"] == \"SSWE\":\n",
    "    data_dir = f\"data/{data_parameters['dataset_name']}/processed/\"\n",
    "    pred_horizon = data_parameters['pred_horizon']\n",
    "    train_data = SSWEDataset(data_dir, test = False, pred_horizon = data_parameters[\"train_horizon\"], return_all = True)\n",
    "    test_data = SSWEDataset(data_dir, test = True, pred_horizon = pred_horizon, return_all = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_parameters[\"dataset_name\"] != \"SSWE\":\n",
    "    domain_range = train_data.get_domain_range()\n",
    "else:\n",
    "    # Requires Longitude and quadrature weights instead of domain range\n",
    "    domain_range = (train_data.get_nlon(), train_data.get_train_weights(), test_data.get_nlon(), test_data.get_eval_weights())  \n",
    "    \n",
    "if data_parameters['dataset_name'] == 'DarcyFlow':\n",
    "    # Validation data on full resolution\n",
    "    train_data, _ = random_split(train_data, lengths = [0.8,0.2], generator = torch.Generator().manual_seed(42))\n",
    "    _, val_data = random_split(train_data_full_res, lengths = [0.8,0.2], generator = torch.Generator().manual_seed(42))\n",
    "elif data_parameters['dataset_name'] != 'ERA5':\n",
    "    train_data, val_data = random_split(train_data, lengths = [0.8,0.2], generator = torch.Generator().manual_seed(42))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = training_parameters['batch_size']\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m in_channels = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))[\u001b[32m0\u001b[39m].shape[\u001b[32m1\u001b[39m]\n\u001b[32m      2\u001b[39m out_channels = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))[\u001b[32m1\u001b[39m].shape[\u001b[32m1\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = train_utils.setup_model(training_parameters, \u001b[43mdevice\u001b[49m, in_channels, out_channels)\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "in_channels = next(iter(train_loader))[0].shape[1]\n",
    "out_channels = next(iter(train_loader))[1].shape[1]\n",
    "\n",
    "model = train_utils.setup_model(training_parameters, device, in_channels, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfno2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
