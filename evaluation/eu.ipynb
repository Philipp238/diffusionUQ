{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from models import UNetDiffusion, UNet_diffusion_normal\n",
    "import torch\n",
    "from models import Diffusion\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data import PDE1D, WeatherBench\n",
    "from torch.distributions.lowrank_multivariate_normal import LowRankMultivariateNormal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import scienceplots\n",
    "\n",
    "import cmcrameri\n",
    "from cmap import Colormap\n",
    "plt.rcParams['image.cmap']= \"viridis\"\n",
    "cmap = Colormap('seaborn:icefire').to_mpl()\n",
    "cmap2 = cmap#Colormap('crameri:lajolla_r').to_mpl()\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d64d40",
   "metadata": {},
   "source": [
    "# Adjust diffusion process to get EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_x_sample(parameter, x):\n",
    "    return parameter.view(*parameter.shape, *(1,) * (x.ndim - parameter.ndim)).expand(\n",
    "        x.shape\n",
    "    )\n",
    "\n",
    "\n",
    "class DistributionalDiffusion(Diffusion):\n",
    "    def __init__(\n",
    "        self,\n",
    "        noise_steps=1000,\n",
    "        noise_schedule=\"linear\",\n",
    "        img_size=256,\n",
    "        device=\"cuda\",\n",
    "        distributional_method=\"normal\",\n",
    "        closed_form=False,\n",
    "        x_T_sampling_method=\"standard\",\n",
    "        ddim_churn=1.0,\n",
    "        beta_endpoints=(1e-4, 0.02),\n",
    "        tau = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            noise_steps=noise_steps,\n",
    "            noise_schedule=noise_schedule,\n",
    "            img_size=img_size,\n",
    "            device=device,\n",
    "            x_T_sampling_method=x_T_sampling_method,\n",
    "            ddim_churn=ddim_churn,\n",
    "            beta_endpoints=beta_endpoints,\n",
    "            tau = tau,\n",
    "        )\n",
    "        self.distributional_method = distributional_method\n",
    "        self.closed_form = closed_form\n",
    "        self.tau = tau\n",
    "\n",
    "    def sample_noise(self, model, x, t, conditioning=None, pred=None):\n",
    "        if self.distributional_method == \"normal\":\n",
    "            predicted_noise = model(x, t, conditioning, pred=pred)\n",
    "            # Calculate epistemic uncertainty\n",
    "            var = predicted_noise[..., 1]\n",
    "            eu = var.squeeze()\n",
    "\n",
    "            predicted_noise = predicted_noise[..., 0] + np.sqrt(self.tau) * predicted_noise[\n",
    "                ..., 1\n",
    "            ] * torch.randn_like(predicted_noise[..., 0], device=self.device)   \n",
    "\n",
    "        elif self.distributional_method == \"mvnormal\":\n",
    "            predicted_noise = model(x, t, conditioning, pred=pred)\n",
    "            if predicted_noise.shape[-1] == predicted_noise.shape[-2] + 1:\n",
    "                # Cholesky\n",
    "                mu = predicted_noise[..., 0]\n",
    "                L_full = np.sqrt(self.tau) * predicted_noise[..., 1:]\n",
    "                mvnorm = MultivariateNormal(loc=mu, scale_tril=L_full)\n",
    "            else:  # Lora\n",
    "                mu = predicted_noise[..., 0]\n",
    "                diag = self.tau * predicted_noise[..., 1]\n",
    "                lora = np.sqrt(self.tau) * predicted_noise[..., 2:]\n",
    "                mvnorm = LowRankMultivariateNormal(mu, lora, diag)\n",
    "            predicted_noise = mvnorm.sample()\n",
    "\n",
    "        elif self.distributional_method == \"sample\":\n",
    "            predicted_noise = model(x, t, conditioning, pred=pred, n_samples=1).squeeze(\n",
    "                -1\n",
    "            )\n",
    "        elif self.distributional_method == \"mixednormal\":\n",
    "            predicted_mixture = model(x, t, conditioning, pred=pred)\n",
    "            mu = predicted_mixture[..., 0]\n",
    "            sigma = np.sqrt(self.tau) * predicted_mixture[..., 1]\n",
    "            weights = predicted_mixture[..., 2]\n",
    "            sampled_weights = torch.distributions.Categorical(weights).sample()\n",
    "            sampled_mu = torch.gather(mu, dim=-1, index=sampled_weights.unsqueeze(-1))\n",
    "            sampled_sigma = torch.gather(\n",
    "                sigma, dim=-1, index=sampled_weights.unsqueeze(-1)\n",
    "            )\n",
    "            predicted_noise = sampled_mu + sampled_sigma * torch.randn_like(\n",
    "                sampled_mu, device=self.device\n",
    "            )\n",
    "            predicted_noise = predicted_noise.squeeze(-1)\n",
    "        return predicted_noise, eu\n",
    "\n",
    "    def sample_low_dimensional(\n",
    "        self, model, n, conditioning=None, cfg_scale=3, pred=None, gt_target=None\n",
    "    ):\n",
    "        model.eval()\n",
    "        eu_array = torch.zeros(n, *self.img_size[1:],self.noise_steps)\n",
    "        with torch.no_grad():\n",
    "            x = self.sample_x_T((n, *self.img_size), pred, inference=True)\n",
    "            for i in reversed(range(1, self.noise_steps)):\n",
    "                t = (torch.ones(n) * i).long().to(self.device)\n",
    "                if self.closed_form and self.distributional_method in [\n",
    "                    \"normal\",\n",
    "                    \"mixednormal\",\n",
    "                    \"mvnormal\",\n",
    "                ]:\n",
    "                    predicted_noise_distribution_params = model(\n",
    "                        x, t, conditioning, pred=pred\n",
    "                    )\n",
    "                    x = self.sample_x_t_closed_form(\n",
    "                        x,\n",
    "                        t,\n",
    "                        predicted_noise_distribution_params,\n",
    "                        pred,\n",
    "                        i,\n",
    "                        method=self.distributional_method,\n",
    "                    )\n",
    "                else:\n",
    "                    predicted_noise, eu = self.sample_noise(model, x, t, conditioning, pred)\n",
    "                    eu_array[...,i] = eu\n",
    "                    if cfg_scale > 0:\n",
    "                        uncond_predicted_noise = self.sample_noise(\n",
    "                            model, x, t, None, pred\n",
    "                        )\n",
    "                        predicted_noise = torch.lerp(\n",
    "                            uncond_predicted_noise, predicted_noise, cfg_scale\n",
    "                        )\n",
    "                    x = self.sample_x_t_inference_DDIM(x, t, predicted_noise, pred, i)\n",
    "\n",
    "        model.train()\n",
    "        return x, eu_array.squeeze()\n",
    "\n",
    "\n",
    "def generate_diffusion_samples_low_dimensional(\n",
    "    model,\n",
    "    input,\n",
    "    n_timesteps,\n",
    "    target_shape,\n",
    "    n_samples,\n",
    "    x_T_sampling_method,\n",
    "    distributional_method=\"deterministic\",\n",
    "    closed_form=False,\n",
    "    regressor=None,\n",
    "    cfg_scale=3,\n",
    "    gt_target=None,\n",
    "    ddim_churn=1.0,\n",
    "    noise_schedule=None,\n",
    "    metrics_plots=False,\n",
    "    beta_endpoints=(1e-4, 0.02),\n",
    "    tau = 1,\n",
    "):\n",
    "    if distributional_method == \"deterministic\":\n",
    "        diffusion = Diffusion(\n",
    "            noise_steps=n_timesteps,\n",
    "            img_size=target_shape[1:],\n",
    "            device=input.device,\n",
    "            x_T_sampling_method=x_T_sampling_method,\n",
    "            ddim_churn=ddim_churn,\n",
    "            noise_schedule=noise_schedule,\n",
    "            beta_endpoints=beta_endpoints,\n",
    "            tau = tau,\n",
    "        )\n",
    "    else:\n",
    "        diffusion = DistributionalDiffusion(\n",
    "            noise_steps=n_timesteps,\n",
    "            img_size=target_shape[1:],\n",
    "            device=input.device,\n",
    "            distributional_method=distributional_method,\n",
    "            closed_form=closed_form,\n",
    "            x_T_sampling_method=x_T_sampling_method,\n",
    "            ddim_churn=ddim_churn,\n",
    "            noise_schedule=noise_schedule,\n",
    "            beta_endpoints=beta_endpoints,\n",
    "            tau = tau,\n",
    "        )\n",
    "\n",
    "    sampled_images = torch.zeros(*target_shape, n_samples).to(input.device)\n",
    "    eu_array = torch.zeros(input.shape[0], *input.shape[2:], n_timesteps, n_samples).to(input.device)\n",
    "    for i in range(n_samples):\n",
    "        with torch.no_grad():\n",
    "            pred, eu = diffusion.sample_low_dimensional(\n",
    "                model,\n",
    "                n=input.shape[0],\n",
    "                conditioning=input,\n",
    "                pred=None,\n",
    "                cfg_scale=cfg_scale,\n",
    "            )\n",
    "            sampled_images[..., i] = pred.detach()\n",
    "            eu_array[...,i] = eu.detach()\n",
    "    return sampled_images, eu_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c9030",
   "metadata": {},
   "source": [
    "# KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0973999",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PDE1D(\n",
    "    data_dir=\"../data/\",\n",
    "    pde=\"KS\",\n",
    "    var=\"test\",\n",
    "    downscaling_factor=1,\n",
    "    normalize=True,\n",
    "    last_t_steps=2,\n",
    "    temporal_downscaling_factor=2,\n",
    "    select_timesteps=\"zero\"\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "target_dim, input_dim = (\n",
    "    (1, *test_dataset.get_dimensions()),\n",
    "    (3, *test_dataset.get_dimensions()),\n",
    ")\n",
    "grid = test_dataset.get_coordinates()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7407bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_scale = 0\n",
    "x_T_sampling_method=\"standard\"\n",
    "n_timesteps = 50\n",
    "n_samples = 25\n",
    "t_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8faaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(test_dataset)\n",
    "indices = np.random.choice(n_test, 3, replace=False)\n",
    "indices = np.array([357, 211, 833])\n",
    "input = []\n",
    "target = []\n",
    "trajectory = []\n",
    "for idx in indices:\n",
    "    target_tensor, input_tensor = test_dataset.get_trajectory(idx, length = n_timesteps)\n",
    "    target_tensor = target_tensor.unsqueeze(0).to(device)\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "    input.append(input_tensor)\n",
    "    target.append(target_tensor[:,:,2]-input_tensor[:,-2])\n",
    "    trajectory.append(target_tensor)\n",
    "input = torch.cat(input, dim=0)\n",
    "target = torch.cat(target, dim=0)\n",
    "trajectory = torch.cat(trajectory, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc891e",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../results/KS/normal/Datetime_20250831_102648_Loss_1D_KS_UNet_diffusion_normal_T50_DDIM1.pt\"\n",
    "distributional_method = \"normal\"\n",
    "beta_endpoints = (0.001, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone =  UNetDiffusion(\n",
    "            d=1,\n",
    "            conditioning_dim=3,\n",
    "            hidden_channels=64,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            init_features=64,\n",
    "            domain_dim = target_dim\n",
    "        )\n",
    "\n",
    "model = UNet_diffusion_normal(\n",
    "    backbone=backbone,\n",
    "    d=1,\n",
    "    target_dim = 1,\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(ckpt_path, map_location=device)\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, eu = generate_diffusion_samples_low_dimensional(\n",
    "    model=model,\n",
    "    input = input,\n",
    "    n_timesteps=n_timesteps,\n",
    "    target_shape=target.shape,\n",
    "    n_samples=n_samples,\n",
    "    distributional_method=distributional_method,\n",
    "    x_T_sampling_method=x_T_sampling_method,\n",
    "    cfg_scale=cfg_scale,\n",
    "    noise_schedule=\"linear\",\n",
    "    beta_endpoints = beta_endpoints,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0da8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_input = input[:,2:3,:]\n",
    "t0 = input[:,1:2,:]\n",
    "full_array = torch.zeros(input.shape[0], 1, input.shape[2], t_steps,n_samples, device=device)\n",
    "eu_array = torch.zeros(input.shape[0],input.shape[2], n_timesteps, n_samples,t_steps)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    autoregressive_input = input.clone()\n",
    "    pred_array = torch.zeros(input.shape[0], 1, input.shape[2], t_steps, device=device)\n",
    "    for t in range(t_steps):\n",
    "        pred, eu = generate_diffusion_samples_low_dimensional(\n",
    "            model=model,\n",
    "            input = autoregressive_input,\n",
    "            n_timesteps=n_timesteps,\n",
    "            target_shape=target.shape,\n",
    "            n_samples=1,\n",
    "            distributional_method=distributional_method,\n",
    "            x_T_sampling_method=x_T_sampling_method,\n",
    "            cfg_scale=cfg_scale,\n",
    "            noise_schedule=\"linear\",\n",
    "            beta_endpoints = beta_endpoints,\n",
    "        )\n",
    "        eu_array[...,i,t] = eu.squeeze()\n",
    "        if t == 0:\n",
    "            pred_array[...,t] = pred.squeeze(-1)+ t0\n",
    "        else:\n",
    "            pred_array[...,t] = pred.squeeze(-1) + pred_array[...,t-1]\n",
    "\n",
    "        if t == 1:\n",
    "            autoregressive_input = torch.cat([t0, pred_array[...,0], grid_input], dim = 1)\n",
    "        elif t > 1:\n",
    "            autoregressive_input = torch.cat([pred_array[...,t-1],pred_array[...,t], grid_input], dim = 1)\n",
    "    # Save\n",
    "    full_array[...,i] = pred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticksize = 33\n",
    "legendsize = 36\n",
    "axissize = 35\n",
    "titlesize = 40\n",
    "plt.style.use([\"science\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2\n",
    "vmin_truth = -2.5\n",
    "vmax_truth = 2.5\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (24,3.5), sharey = True, layout = \"constrained\")\n",
    "axs = axs.ravel()\n",
    "cbs = []\n",
    "\n",
    "im2 = axs[0].pcolormesh(full_array[b,0].mean(dim = -1).cpu(), cmap = cmap, rasterized = True, vmin = vmin_truth, vmax = vmax_truth)\n",
    "axs[0].set_title(\"Mean prediction\", fontsize = titlesize)\n",
    "cb1 = fig.colorbar(im2, ax = axs[0], pad = 0.01)\n",
    "cbs.append(cb1)\n",
    "\n",
    "im3 = axs[1].pcolormesh(full_array[b,0].var(axis = -1).cpu(), cmap = cmap2, rasterized = True)\n",
    "axs[1].set_title(\"Aleatoric uncertainty\", fontsize = titlesize)\n",
    "cb1 = fig.colorbar(im3, ax = axs[1], pad = 0.01)\n",
    "cbs.append(cb1)\n",
    "\n",
    "im4 = axs[2].pcolormesh(eu_array[b].mean(dim = (1,2)).cpu(), cmap = cmap2,  rasterized = True)\n",
    "axs[2].set_title(\"Epistemic uncertainty\", fontsize = titlesize)\n",
    "cb1 = fig.colorbar(im4, ax = axs[2], pad = 0.01)\n",
    "cbs.append(cb1)\n",
    "\n",
    "\n",
    "\n",
    "axs[0].yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "axs[0].set_ylabel(\"x\", fontsize = axissize)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"s\", fontsize = axissize) \n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=ticksize)\n",
    "\n",
    "for cb in cbs:\n",
    "    cb.ax.tick_params(labelsize=legendsize)\n",
    "\n",
    "\n",
    "plt.savefig(\"plots/KS_eu_small.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticksize = 29\n",
    "legendsize = 32\n",
    "axissize = 31\n",
    "titlesize = 36\n",
    "plt.style.use([\"science\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ccc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2\n",
    "\n",
    "fig = plt.figure(figsize=(25, 5))\n",
    "\n",
    "# Outer grid: 2 rows × 2 columns\n",
    "outer = gridspec.GridSpec(2, 2, figure=fig, width_ratios=[1, 2], wspace=0.1, hspace=0.15)\n",
    "\n",
    "# Right block: a 2×2 inside the right column\n",
    "right_gs = gridspec.GridSpecFromSubplotSpec(\n",
    "    2, 2, subplot_spec=outer[:, 1], wspace=0.1, hspace=0.3\n",
    ")\n",
    "\n",
    "axs = [\n",
    "    fig.add_subplot(right_gs[0, 0]),\n",
    "    fig.add_subplot(right_gs[0, 1]),\n",
    "    fig.add_subplot(right_gs[1, 0]),\n",
    "    fig.add_subplot(right_gs[1, 1]),\n",
    "]\n",
    "\n",
    "cbs = []\n",
    "\n",
    "# Left subplot: put in the middle between top and bottom\n",
    "# → we compute its size from one right subplot and align manually\n",
    "pos_top = axs[0].get_position()\n",
    "pos_bottom = axs[2].get_position()\n",
    "\n",
    "# Same height as one of the right plots\n",
    "height = pos_top.height\n",
    "# Same vertical center as the 2×2 block\n",
    "center_y = (pos_top.y0 + pos_bottom.y1) / 2\n",
    "\n",
    "# Manually add left axis with matching size\n",
    "ax_left = fig.add_axes([0.12, center_y - height/2, pos_top.width, height])\n",
    "\n",
    "# --- Plots ---\n",
    "vmin_truth = -2.5\n",
    "vmax_truth = 2.5\n",
    "im1 = axs[0].pcolormesh(full_array[b,0,...,0].cpu(), cmap=cmap, rasterized = True, vmin = vmin_truth, vmax = vmax_truth)\n",
    "axs[0].set_title(\"Sample trajectory\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im1, ax=axs[0], pad = 0.02))\n",
    "\n",
    "im3 = axs[1].pcolormesh(full_array[b,0].var(axis=-1).cpu(), cmap=cmap2, rasterized = True)\n",
    "axs[1].set_title(\"Aleatoric uncertainty\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im3, ax=axs[1], pad = 0.02))\n",
    "\n",
    "im2 = axs[2].pcolormesh(full_array[b,0].mean(dim=-1).cpu(), cmap=cmap, rasterized = True, vmin = vmin_truth, vmax = vmax_truth)\n",
    "axs[2].set_title(\"Mean prediction\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im2, ax=axs[2], pad = 0.02))\n",
    "\n",
    "im4 = axs[3].pcolormesh(eu_array[b].mean(dim=(1,2)).cpu(), cmap=cmap2, rasterized = True)\n",
    "axs[3].set_title(\"Epistemic uncertainty\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im4, ax=axs[3], pad = 0.02))\n",
    "\n",
    "# Left plot\n",
    "im_left = ax_left.pcolormesh(trajectory[b,0,2:].t().cpu(), cmap=cmap, rasterized = True, vmin = vmin_truth, vmax = vmax_truth)\n",
    "ax_left.set_title(\"Ground truth\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im_left, ax=ax_left, pad = 0.02))\n",
    "\n",
    "# Add labels\n",
    "# Hide x-ticks on the top row\n",
    "for ax in [axs[0], axs[1]]:\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "# Hide y-ticks on the right column\n",
    "for ax in [axs[1], axs[3]]:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "for ax in [ax_left] + [axs[0], axs[2]]:\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "\n",
    "for ax in [ax_left] + [axs[2], axs[3]]:\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "# Add labels only where needed\n",
    "axs[2].set_xlabel(\"s\", fontsize = axissize)   # bottom left\n",
    "axs[3].set_xlabel(\"s\", fontsize = axissize)   # bottom right\n",
    "axs[0].set_ylabel(\"x\", fontsize = axissize)   # top left\n",
    "axs[2].set_ylabel(\"x\", fontsize = axissize)   # bottom left\n",
    "\n",
    "# Do the same for the left (truth) plot\n",
    "ax_left.set_xlabel(\"s\", fontsize = axissize)\n",
    "ax_left.set_ylabel(\"x\", fontsize = axissize)\n",
    "\n",
    "for ax in [ax_left] + axs:\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=ticksize)\n",
    "\n",
    "for cb in cbs:\n",
    "    cb.ax.tick_params(labelsize=legendsize)\n",
    "\n",
    "plt.savefig(\"plots/KS_eu.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e5805",
   "metadata": {},
   "source": [
    "# Burgers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336014f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PDE1D(\n",
    "    data_dir=\"../data/\",\n",
    "    pde=\"Burgers\",\n",
    "    var=\"test\",\n",
    "    downscaling_factor=4,\n",
    "    normalize=True,\n",
    "    last_t_steps=2,\n",
    "    temporal_downscaling_factor=2,\n",
    "    select_timesteps=\"zero\"\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "target_dim, input_dim = (\n",
    "    (1, *test_dataset.get_dimensions()),\n",
    "    (3, *test_dataset.get_dimensions()),\n",
    ")\n",
    "grid = test_dataset.get_coordinates()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19bcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_scale = 0\n",
    "x_T_sampling_method=\"standard\"\n",
    "n_timesteps = 50\n",
    "n_samples = 25\n",
    "t_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b441594",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(test_dataset)\n",
    "indices = np.random.choice(n_test, 3, replace=False)\n",
    "indices = np.array([357, 211, 833])\n",
    "input = []\n",
    "target = []\n",
    "trajectory = []\n",
    "for idx in indices:\n",
    "    target_tensor, input_tensor = test_dataset.get_trajectory(idx, length = n_timesteps)\n",
    "    target_tensor = target_tensor.unsqueeze(0).to(device)\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "    input.append(input_tensor)\n",
    "    target.append(target_tensor[:,:,2]-input_tensor[:,-2])\n",
    "    trajectory.append(target_tensor)\n",
    "input = torch.cat(input, dim=0)\n",
    "target = torch.cat(target, dim=0)\n",
    "trajectory = torch.cat(trajectory, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736625de",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../results/Burgers/normal/Datetime_20250829_011108_Loss_1D_Burgers_UNet_diffusion_normal_T50_DDIM1.pt\"\n",
    "distributional_method = \"normal\"\n",
    "beta_endpoints = (0.001, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone =  UNetDiffusion(\n",
    "            d=1,\n",
    "            conditioning_dim=3,\n",
    "            hidden_channels=64,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            init_features=64,\n",
    "            domain_dim = target_dim\n",
    "        )\n",
    "\n",
    "model = UNet_diffusion_normal(\n",
    "    backbone=backbone,\n",
    "    d=1,\n",
    "    target_dim = 1,\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(ckpt_path, map_location=device)\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bbb902",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, eu = generate_diffusion_samples_low_dimensional(\n",
    "    model=model,\n",
    "    input = input,\n",
    "    n_timesteps=n_timesteps,\n",
    "    target_shape=target.shape,\n",
    "    n_samples=n_samples,\n",
    "    distributional_method=distributional_method,\n",
    "    x_T_sampling_method=x_T_sampling_method,\n",
    "    cfg_scale=cfg_scale,\n",
    "    noise_schedule=\"linear\",\n",
    "    beta_endpoints = beta_endpoints,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_input = input[:,2:3,:]\n",
    "t0 = input[:,1:2,:]\n",
    "full_array = torch.zeros(input.shape[0], 1, input.shape[2], t_steps,n_samples, device=device)\n",
    "eu_array = torch.zeros(input.shape[0],input.shape[2], n_timesteps, n_samples,t_steps)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    autoregressive_input = input.clone()\n",
    "    pred_array = torch.zeros(input.shape[0], 1, input.shape[2], t_steps, device=device)\n",
    "    for t in range(t_steps):\n",
    "        pred, eu = generate_diffusion_samples_low_dimensional(\n",
    "            model=model,\n",
    "            input = autoregressive_input,\n",
    "            n_timesteps=n_timesteps,\n",
    "            target_shape=target.shape,\n",
    "            n_samples=1,\n",
    "            distributional_method=distributional_method,\n",
    "            x_T_sampling_method=x_T_sampling_method,\n",
    "            cfg_scale=cfg_scale,\n",
    "            noise_schedule=\"linear\",\n",
    "            beta_endpoints = beta_endpoints,\n",
    "        )\n",
    "        eu_array[...,i,t] = eu.squeeze()\n",
    "        if t == 0:\n",
    "            pred_array[...,t] = pred.squeeze(-1)+ t0\n",
    "        else:\n",
    "            pred_array[...,t] = pred.squeeze(-1) + pred_array[...,t-1]\n",
    "\n",
    "        if t == 1:\n",
    "            autoregressive_input = torch.cat([t0, pred_array[...,0], grid_input], dim = 1)\n",
    "        elif t > 1:\n",
    "            autoregressive_input = torch.cat([pred_array[...,t-1],pred_array[...,t], grid_input], dim = 1)\n",
    "    # Save\n",
    "    full_array[...,i] = pred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_array.shape, trajectory.shape, eu_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ff12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticksize = 31\n",
    "legendsize = 34\n",
    "axissize = 33\n",
    "titlesize = 38\n",
    "plt.style.use([\"science\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd049160",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2\n",
    "\n",
    "fig = plt.figure(figsize=(25, 5))\n",
    "\n",
    "# Outer grid: 2 rows × 2 columns\n",
    "outer = gridspec.GridSpec(2, 2, figure=fig, width_ratios=[1, 2], wspace=0.1, hspace=0.15)\n",
    "\n",
    "# Right block: a 2×2 inside the right column\n",
    "right_gs = gridspec.GridSpecFromSubplotSpec(\n",
    "    2, 2, subplot_spec=outer[:, 1], wspace=0.1, hspace=0.3\n",
    ")\n",
    "\n",
    "axs = [\n",
    "    fig.add_subplot(right_gs[0, 0]),\n",
    "    fig.add_subplot(right_gs[0, 1]),\n",
    "    fig.add_subplot(right_gs[1, 0]),\n",
    "    fig.add_subplot(right_gs[1, 1]),\n",
    "]\n",
    "\n",
    "cbs = []\n",
    "\n",
    "# Left subplot: put in the middle between top and bottom\n",
    "# → we compute its size from one right subplot and align manually\n",
    "pos_top = axs[0].get_position()\n",
    "pos_bottom = axs[2].get_position()\n",
    "\n",
    "# Same height as one of the right plots\n",
    "height = pos_top.height\n",
    "# Same vertical center as the 2×2 block\n",
    "center_y = (pos_top.y0 + pos_bottom.y1) / 2\n",
    "\n",
    "# Manually add left axis with matching size\n",
    "ax_left = fig.add_axes([0.12, center_y - height/2, pos_top.width, height])\n",
    "\n",
    "# --- Plots ---\n",
    "vmin_truth = -1.2\n",
    "vmax_truth = 2.2\n",
    "im1 = axs[0].pcolormesh(full_array[b,0,...,0].cpu(), cmap=cmap, rasterized = True, vmin = vmin_truth, vmax = vmax_truth)\n",
    "axs[0].set_title(\"Sample trajectory\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im1, ax=axs[0], pad = 0.02))\n",
    "\n",
    "im3 = axs[1].pcolormesh(full_array[b,0].var(axis=-1).cpu(), cmap=cmap2, rasterized = True)\n",
    "axs[1].set_title(\"Aleatoric uncertainty\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im3, ax=axs[1], pad = 0.02))\n",
    "\n",
    "im2 = axs[2].pcolormesh(full_array[b,0].mean(dim=-1).cpu(), cmap=cmap, rasterized = True, vmin = vmin_truth, vmax = vmax_truth)\n",
    "axs[2].set_title(\"Mean prediction\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im2, ax=axs[2], pad = 0.02))\n",
    "\n",
    "im4 = axs[3].pcolormesh(eu_array[b].mean(dim=(1,2)).cpu(), cmap=cmap2, rasterized = True)\n",
    "axs[3].set_title(\"Epistemic uncertainty\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im4, ax=axs[3], pad = 0.02))\n",
    "\n",
    "# Left plot\n",
    "im_left = ax_left.pcolormesh(trajectory[b,0,2:].t().cpu(), cmap=cmap, rasterized = True, vmin = vmin_truth, vmax = vmax_truth)\n",
    "ax_left.set_title(\"Ground truth\", fontsize = titlesize)\n",
    "cbs.append(fig.colorbar(im_left, ax=ax_left, pad = 0.02))\n",
    "\n",
    "# Add labels\n",
    "# Hide x-ticks on the top row\n",
    "for ax in [axs[0], axs[1]]:\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "# Hide y-ticks on the right column\n",
    "for ax in [axs[1], axs[3]]:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "for ax in [ax_left] + [axs[0], axs[2]]:\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "\n",
    "for ax in [ax_left] + [axs[2], axs[3]]:\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "# Add labels only where needed\n",
    "axs[2].set_xlabel(\"s\", fontsize = axissize)   # bottom left\n",
    "axs[3].set_xlabel(\"s\", fontsize = axissize)   # bottom right\n",
    "axs[0].set_ylabel(\"x\", fontsize = axissize)   # top left\n",
    "axs[2].set_ylabel(\"x\", fontsize = axissize)   # bottom left\n",
    "\n",
    "# Do the same for the left (truth) plot\n",
    "ax_left.set_xlabel(\"s\", fontsize = axissize)\n",
    "ax_left.set_ylabel(\"x\", fontsize = axissize)\n",
    "\n",
    "for ax in [ax_left] + axs:\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=ticksize)\n",
    "\n",
    "for cb in cbs:\n",
    "    cb.ax.tick_params(labelsize=legendsize)\n",
    "\n",
    "plt.savefig(\"plots/Burgers_eu.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a44de2",
   "metadata": {},
   "source": [
    "# WeatherBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acba6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WeatherBench(\n",
    "    var=\"test\",\n",
    "    downscaling_factor=1,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "target_dim, input_dim = (\n",
    "    (1, *test_dataset.get_dimensions()),\n",
    "    (3, *test_dataset.get_dimensions()),\n",
    ")\n",
    "lat_lon, t= test_dataset.get_grid()\n",
    "lat,lon = lat_lon\n",
    "\n",
    "# Index of input t2m\n",
    "t2m = 1\n",
    "ll,t = test_dataset.get_grid()\n",
    "lat, lon = ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_scale = 0\n",
    "x_T_sampling_method=\"standard\"\n",
    "n_timesteps = 50\n",
    "n_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39324451",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5\n",
    "target, input = test_dataset[idx]\n",
    "target = target.unsqueeze(0).to(device)\n",
    "input = input.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../results/T2M/normal/Datetime_20250908_031720_Loss_WeatherBench_UNet_diffusion_normal_T50_DDIM1.pt\"\n",
    "distributional_method = \"normal\"\n",
    "beta_endpoints = (0.001, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ef8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone =  UNetDiffusion(\n",
    "            d=2,\n",
    "            conditioning_dim=12,\n",
    "            hidden_channels=64,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            init_features=64,\n",
    "            domain_dim = target_dim\n",
    "        )\n",
    "\n",
    "model = UNet_diffusion_normal(\n",
    "    backbone=backbone,\n",
    "    d=2,\n",
    "    target_dim = 1,\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(ckpt_path, map_location=device)\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e251e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, eu = generate_diffusion_samples_low_dimensional(\n",
    "    model=model,\n",
    "    input = input,\n",
    "    n_timesteps=n_timesteps,\n",
    "    target_shape=target.shape,\n",
    "    n_samples=n_samples,\n",
    "    distributional_method=distributional_method,\n",
    "    x_T_sampling_method=x_T_sampling_method,\n",
    "    cfg_scale=cfg_scale,\n",
    "    noise_schedule=\"linear\",\n",
    "    beta_endpoints=beta_endpoints\n",
    ")\n",
    "\n",
    "input_last_t = input[:,t2m].cpu()\n",
    "pred = pred.cpu().squeeze() + input_last_t.unsqueeze(-1)\n",
    "pred = test_dataset.destandardize_output(pred) - 273.15\n",
    "target = target.cpu().squeeze() + input_last_t\n",
    "target = test_dataset.destandardize_output(target) - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087f497",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a43d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticksize = 18\n",
    "legendsize = 21\n",
    "axissize = 20\n",
    "titlesize = 22\n",
    "plt.style.use([\"science\"])\n",
    "\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf524186",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin_truth = target[b].min()\n",
    "vmax_truth = target[b].max()\n",
    "s=0\n",
    "\n",
    "error_cmap = Colormap('seaborn:icefire').to_mpl()\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Make a 2×3 grid: left col has one subplot spanning both rows,\n",
    "# right 2×2 block are normal subplots\n",
    "outer = gridspec.GridSpec(2, 3, figure=fig, width_ratios=[1, 0.85, 1],\n",
    "                            wspace=0.2, hspace=0.1)\n",
    "\n",
    "\n",
    "# Right block: 2×2 grid inside columns 1–2\n",
    "right_gs = gridspec.GridSpecFromSubplotSpec(\n",
    "    2, 2, subplot_spec=outer[:, 1:], wspace=0.05, hspace=0.1\n",
    ")\n",
    "\n",
    "axs = [\n",
    "    fig.add_subplot(right_gs[0, 0], projection=ccrs.PlateCarree()),\n",
    "    fig.add_subplot(right_gs[0, 1], projection=ccrs.PlateCarree()),\n",
    "    fig.add_subplot(right_gs[1, 0], projection=ccrs.PlateCarree()),\n",
    "    fig.add_subplot(right_gs[1, 1], projection=ccrs.PlateCarree()),\n",
    "]\n",
    "\n",
    "# Left panel: put it in the left column spanning both rows\n",
    "ax_left = fig.add_subplot(outer[:, 0], projection=ccrs.PlateCarree())\n",
    "\n",
    "# Now adjust its position to match the height of one right-hand subplot,\n",
    "# and center it vertically.\n",
    "ref_top = axs[0].get_position()     # top-right subplot\n",
    "ref_bottom = axs[2].get_position()  # bottom-right subplot\n",
    "ref_height = ref_top.height\n",
    "ref_center_y = (ref_top.y0 + ref_bottom.y1) / 2\n",
    "\n",
    "# Keep the left subplot's width, but reset its vertical placement\n",
    "pos = ax_left.get_position()\n",
    "ax_left.set_position([pos.x0, ref_center_y - ref_height/2,\n",
    "                    pos.width, ref_height])\n",
    "\n",
    "cbs = []\n",
    "\n",
    "# --- Plots ---\n",
    "im_left = ax_left.pcolormesh(lon, lat, target[b], shading=\"nearest\",\n",
    "                                rasterized=True, vmin=vmin_truth, vmax=vmax_truth, cmap=\"cmc.vik\")\n",
    "ax_left.set_title(\"Ground truth\", fontsize=titlesize)\n",
    "cbs.append(fig.colorbar(im_left, ax=ax_left, shrink=0.375, pad = 0.02))\n",
    "\n",
    "im1 = axs[0].pcolormesh(lon, lat, pred[b, ..., s].numpy(), shading=\"nearest\",\n",
    "                        rasterized=True, vmin=vmin_truth, vmax=vmax_truth, cmap=\"cmc.vik\")\n",
    "axs[0].set_title(\"Diffusion sample\", size=titlesize)\n",
    "cbs.append(fig.colorbar(im1, ax=axs[0], shrink=0.783, pad = 0.02))\n",
    "\n",
    "im2 = axs[1].pcolormesh(lon, lat, pred[b,...,].var(dim = -1).numpy(), shading = \"nearest\", cmap = cmap, rasterized = True)\n",
    "axs[1].set_title(\"Aleatoric uncertainty\", size=titlesize)\n",
    "cbs.append(fig.colorbar(im2, ax=axs[1], shrink=0.783, pad = 0.02))\n",
    "\n",
    "im3 = axs[2].pcolormesh(lon, lat, pred[b].mean(dim=-1).numpy(), shading=\"nearest\",\n",
    "                        rasterized=True, vmin=vmin_truth, vmax=vmax_truth, cmap=\"cmc.vik\")\n",
    "axs[2].set_title(\"Mean prediction\", size=titlesize)\n",
    "cbs.append(fig.colorbar(im3, ax=axs[2], shrink=0.783, pad = 0.02))\n",
    "\n",
    "im3 = axs[3].pcolormesh(lon, lat, eu[b].mean(dim = (-2,-1)).cpu().numpy(),shading = \"nearest\", cmap = cmap, rasterized = True)\n",
    "axs[3].set_title(\"Epistemic uncertainty\", size=titlesize)\n",
    "cbs.append(fig.colorbar(im3, ax=axs[3], shrink=0.783, pad = 0.02))\n",
    "\n",
    "for ax in axs + [ax_left]:\n",
    "    ax.set_extent([lon[0]-360, lon[-1], lat[0], lat[-1]], crs=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.COASTLINE, alpha = 0.8)\n",
    "\n",
    "for ax in axs + [ax_left]:\n",
    "    gl = ax.gridlines(draw_labels={\"bottom\":\"x\"}, dms=True, x_inline=False, y_inline=False)\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.xlabel_style = {'size':ticksize}\n",
    "\n",
    "for ax in [ax_left, axs[0], axs[2]]:\n",
    "    gl = ax.gridlines(draw_labels={\"left\":\"y\"}, dms=True, x_inline=False, y_inline=False)\n",
    "    gl.xlines = False\n",
    "    gl.ylines = False\n",
    "    gl.ylabel_style = {'size':ticksize}\n",
    "\n",
    "\n",
    "for cb in cbs:\n",
    "    cb.ax.tick_params(labelsize=legendsize)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"plots/T2M_eu.pdf\", bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
