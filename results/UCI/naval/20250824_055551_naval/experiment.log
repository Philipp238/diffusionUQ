INFO:root:Starting the logger.
INFO:root:Using device cuda.
INFO:root:Using 4 threads
INFO:root:: mem (CPU python)=595.515625MB; mem (CPU total)=15558.06640625MB
INFO:root:############### Starting experiment with config file configs_250814_CARD_sampling_and_epochs_likeCARD/naval.ini ###############
INFO:root:###1 out of 4 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'naval-propulsion-plant', 'downscaling_factor': 1, 'yarin_gal_uci_split_indices': 9, 'max_dataset_size': 1000, 'standardize': True, 'select_timesteps': 'zero', 'temporal_downscaling_factor': 1, 'validation_ratio': 0.0}
INFO:root:After loading the datasets: mem (CPU python)=595.515625MB; mem (CPU total)=15558.06640625MB
INFO:root:###1 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'deterministic', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=2127.76953125MB; mem (CPU total)=16849.578125MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421505.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3162.3046875MB; mem (CPU total)=17709.65625MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.8065
INFO:train:t_training_med: 0.80588
INFO:train:t_training_std: 0.0039
INFO:train:After finishing all epochs: mem (CPU python)=3176.96875MB; mem (CPU total)=17714.94140625MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 4676.423s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 4.75s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00012
INFO:root:EnergyScoreTrain: 7e-05
INFO:root:CRPSTrain: 7e-05
INFO:root:Gaussian NLLTrain: 47.11578
INFO:root:CoverageTrain: 0.18462
INFO:root:QICETrain: 0.13412
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 4.579s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00013
INFO:root:EnergyScoreTest: 8e-05
INFO:root:CRPSTest: 8e-05
INFO:root:Gaussian NLLTest: 57.01006
INFO:root:CoverageTest: 0.20285
INFO:root:QICETest: 0.12899
INFO:root:After validation: mem (CPU python)=3224.6953125MB; mem (CPU total)=17756.0859375MB
INFO:root:###2 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'normal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3224.94140625MB; mem (CPU total)=17756.08203125MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421763.0
INFO:train:GPU memory allocated: 31457280
INFO:train:After setting up the model: mem (CPU python)=3224.94140625MB; mem (CPU total)=17756.08203125MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.98233
INFO:train:t_training_med: 0.98288
INFO:train:t_training_std: 0.01359
INFO:train:After finishing all epochs: mem (CPU python)=3227.93359375MB; mem (CPU total)=15615.27734375MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5549.567s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 6.393s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00012
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -7.98482
INFO:root:CoverageTrain: 0.95047
INFO:root:QICETrain: 0.01883
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 6.096s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00012
INFO:root:EnergyScoreTest: 6e-05
INFO:root:CRPSTest: 6e-05
INFO:root:Gaussian NLLTest: -7.93907
INFO:root:CoverageTest: 0.94552
INFO:root:QICETest: 0.01903
INFO:root:After validation: mem (CPU python)=3229.09765625MB; mem (CPU total)=15615.45703125MB
INFO:root:###3 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'sample', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3229.09765625MB; mem (CPU total)=15615.45703125MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421633.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3229.09765625MB; mem (CPU total)=15615.45703125MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.94936
INFO:train:t_training_med: 0.94907
INFO:train:t_training_std: 0.00629
INFO:train:After finishing all epochs: mem (CPU python)=3229.09765625MB; mem (CPU total)=16540.9296875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5375.82s.
INFO:root:Emptying the cuda cache took 0.001s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 5.994s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00011
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -8.06847
INFO:root:CoverageTrain: 0.94675
INFO:root:QICETrain: 0.00917
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 5.615s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00012
INFO:root:EnergyScoreTest: 5e-05
INFO:root:CRPSTest: 5e-05
INFO:root:Gaussian NLLTest: -8.0001
INFO:root:CoverageTest: 0.93294
INFO:root:QICETest: 0.01048
INFO:root:After validation: mem (CPU python)=3229.75390625MB; mem (CPU total)=16540.796875MB
INFO:root:###4 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'mixednormal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3229.75390625MB; mem (CPU total)=16540.796875MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 522123.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3229.75390625MB; mem (CPU total)=16540.796875MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 1.39745
INFO:train:t_training_med: 1.39758
INFO:train:t_training_std: 0.00836
INFO:train:After finishing all epochs: mem (CPU python)=3230.32421875MB; mem (CPU total)=16544.1796875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 7616.812s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 8.848s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00012
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -7.94213
INFO:root:CoverageTrain: 0.96704
INFO:root:QICETrain: 0.03931
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 8.4s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00012
INFO:root:EnergyScoreTest: 6e-05
INFO:root:CRPSTest: 6e-05
INFO:root:Gaussian NLLTest: -7.88068
INFO:root:CoverageTest: 0.96228
INFO:root:QICETest: 0.03814
INFO:root:After validation: mem (CPU python)=3230.90625MB; mem (CPU total)=16543.02734375MB
INFO:root:###2 out of 4 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'naval-propulsion-plant', 'downscaling_factor': 1, 'yarin_gal_uci_split_indices': 10, 'max_dataset_size': 1000, 'standardize': True, 'select_timesteps': 'zero', 'temporal_downscaling_factor': 1, 'validation_ratio': 0.0}
INFO:root:After loading the datasets: mem (CPU python)=3230.90625MB; mem (CPU total)=16543.02734375MB
INFO:root:###1 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'deterministic', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3230.90625MB; mem (CPU total)=16543.02734375MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421505.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3230.90625MB; mem (CPU total)=16543.02734375MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.79506
INFO:train:t_training_med: 0.79428
INFO:train:t_training_std: 0.00671
INFO:train:After finishing all epochs: mem (CPU python)=3230.90625MB; mem (CPU total)=16551.41796875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 4599.914s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 4.574s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00015
INFO:root:EnergyScoreTrain: 0.0001
INFO:root:CRPSTrain: 9e-05
INFO:root:Gaussian NLLTrain: 18.45811
INFO:root:CoverageTrain: 0.19924
INFO:root:QICETrain: 0.12941
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 4.412s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00015
INFO:root:EnergyScoreTest: 0.0001
INFO:root:CRPSTest: 0.0001
INFO:root:Gaussian NLLTest: 17.34993
INFO:root:CoverageTest: 0.17854
INFO:root:QICETest: 0.132
INFO:root:After validation: mem (CPU python)=3235.51953125MB; mem (CPU total)=16555.76171875MB
INFO:root:###2 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'normal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3235.51953125MB; mem (CPU total)=16555.76171875MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421763.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3235.51953125MB; mem (CPU total)=16555.76171875MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.96866
INFO:train:t_training_med: 0.96821
INFO:train:t_training_std: 0.00619
INFO:train:After finishing all epochs: mem (CPU python)=3235.51953125MB; mem (CPU total)=16554.55078125MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5471.607s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 6.54s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00011
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -8.11682
INFO:root:CoverageTrain: 0.95205
INFO:root:QICETrain: 0.00837
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 6.2s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00012
INFO:root:EnergyScoreTest: 5e-05
INFO:root:CRPSTest: 5e-05
INFO:root:Gaussian NLLTest: -8.04692
INFO:root:CoverageTest: 0.94216
INFO:root:QICETest: 0.00862
INFO:root:After validation: mem (CPU python)=3235.87890625MB; mem (CPU total)=16554.375MB
INFO:root:###3 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'sample', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3235.87890625MB; mem (CPU total)=16554.375MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421633.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3235.87890625MB; mem (CPU total)=16554.375MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.95087
INFO:train:t_training_med: 0.95017
INFO:train:t_training_std: 0.00597
INFO:train:After finishing all epochs: mem (CPU python)=3235.87890625MB; mem (CPU total)=16554.2265625MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5384.525s.
INFO:root:Emptying the cuda cache took 0.001s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 6.018s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00011
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -8.05722
INFO:root:CoverageTrain: 0.95224
INFO:root:QICETrain: 0.01906
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 5.715s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00012
INFO:root:EnergyScoreTest: 5e-05
INFO:root:CRPSTest: 5e-05
INFO:root:Gaussian NLLTest: -7.98299
INFO:root:CoverageTest: 0.94132
INFO:root:QICETest: 0.01769
INFO:root:After validation: mem (CPU python)=3236.3046875MB; mem (CPU total)=16554.40625MB
INFO:root:###4 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'mixednormal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.3046875MB; mem (CPU total)=16554.40625MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 522123.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3236.3046875MB; mem (CPU total)=16554.40625MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 1.40336
INFO:train:t_training_med: 1.40316
INFO:train:t_training_std: 0.01005
INFO:train:After finishing all epochs: mem (CPU python)=3236.3046875MB; mem (CPU total)=13839.64453125MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 7647.218s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 8.824s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00011
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -8.09962
INFO:root:CoverageTrain: 0.94423
INFO:root:QICETrain: 0.00841
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 8.432s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00012
INFO:root:EnergyScoreTest: 5e-05
INFO:root:CRPSTest: 5e-05
INFO:root:Gaussian NLLTest: -8.04654
INFO:root:CoverageTest: 0.943
INFO:root:QICETest: 0.00852
INFO:root:After validation: mem (CPU python)=3236.421875MB; mem (CPU total)=13838.90234375MB
INFO:root:###3 out of 4 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'naval-propulsion-plant', 'downscaling_factor': 1, 'yarin_gal_uci_split_indices': 11, 'max_dataset_size': 1000, 'standardize': True, 'select_timesteps': 'zero', 'temporal_downscaling_factor': 1, 'validation_ratio': 0.0}
INFO:root:After loading the datasets: mem (CPU python)=3236.421875MB; mem (CPU total)=13838.109375MB
INFO:root:###1 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'deterministic', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.421875MB; mem (CPU total)=13838.109375MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421505.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3236.421875MB; mem (CPU total)=13838.109375MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.79196
INFO:train:t_training_med: 0.79071
INFO:train:t_training_std: 0.00592
INFO:train:After finishing all epochs: mem (CPU python)=3236.421875MB; mem (CPU total)=13841.6875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 4586.026s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 4.563s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00015
INFO:root:EnergyScoreTrain: 9e-05
INFO:root:CRPSTrain: 9e-05
INFO:root:Gaussian NLLTrain: 48.03739
INFO:root:CoverageTrain: 0.19281
INFO:root:QICETrain: 0.1351
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 4.431s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00015
INFO:root:EnergyScoreTest: 9e-05
INFO:root:CRPSTest: 9e-05
INFO:root:Gaussian NLLTest: 43.38565
INFO:root:CoverageTest: 0.20788
INFO:root:QICETest: 0.13334
INFO:root:After validation: mem (CPU python)=3236.453125MB; mem (CPU total)=13841.8046875MB
INFO:root:###2 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'normal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.453125MB; mem (CPU total)=13841.8046875MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421763.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3236.453125MB; mem (CPU total)=13841.8046875MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.97057
INFO:train:t_training_med: 0.96942
INFO:train:t_training_std: 0.00744
INFO:train:After finishing all epochs: mem (CPU python)=3236.453125MB; mem (CPU total)=13909.328125MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5484.704s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 6.502s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00013
INFO:root:EnergyScoreTrain: 6e-05
INFO:root:CRPSTrain: 6e-05
INFO:root:Gaussian NLLTrain: -7.86284
INFO:root:CoverageTrain: 0.89554
INFO:root:QICETrain: 0.04787
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 6.211s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00014
INFO:root:EnergyScoreTest: 6e-05
INFO:root:CRPSTest: 6e-05
INFO:root:Gaussian NLLTest: -7.81183
INFO:root:CoverageTest: 0.88516
INFO:root:QICETest: 0.04825
INFO:root:After validation: mem (CPU python)=3236.453125MB; mem (CPU total)=13909.16796875MB
INFO:root:###3 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'sample', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.453125MB; mem (CPU total)=13909.19921875MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421633.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3236.453125MB; mem (CPU total)=13909.19921875MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.95235
INFO:train:t_training_med: 0.95277
INFO:train:t_training_std: 0.01264
INFO:train:After finishing all epochs: mem (CPU python)=3236.453125MB; mem (CPU total)=12393.140625MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5395.821s.
INFO:root:Emptying the cuda cache took 0.001s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 5.909s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00014
INFO:root:EnergyScoreTrain: 6e-05
INFO:root:CRPSTrain: 6e-05
INFO:root:Gaussian NLLTrain: -8.02264
INFO:root:CoverageTrain: 0.91807
INFO:root:QICETrain: 0.0061
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 5.61s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00014
INFO:root:EnergyScoreTest: 6e-05
INFO:root:CRPSTest: 6e-05
INFO:root:Gaussian NLLTest: -8.01318
INFO:root:CoverageTest: 0.92205
INFO:root:QICETest: 0.00852
INFO:root:After validation: mem (CPU python)=3236.453125MB; mem (CPU total)=12393.55078125MB
INFO:root:###4 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'mixednormal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.453125MB; mem (CPU total)=12393.55078125MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 522123.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3236.453125MB; mem (CPU total)=12393.55078125MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 1.40309
INFO:train:t_training_med: 1.40234
INFO:train:t_training_std: 0.00911
INFO:train:After finishing all epochs: mem (CPU python)=3236.453125MB; mem (CPU total)=12379.203125MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 7648.04s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 8.864s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00012
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -8.04044
INFO:root:CoverageTrain: 0.96741
INFO:root:QICETrain: 0.02315
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 8.443s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00013
INFO:root:EnergyScoreTest: 6e-05
INFO:root:CRPSTest: 6e-05
INFO:root:Gaussian NLLTest: -8.01826
INFO:root:CoverageTest: 0.96563
INFO:root:QICETest: 0.02406
INFO:root:After validation: mem (CPU python)=3236.51171875MB; mem (CPU total)=12378.3984375MB
INFO:root:###4 out of 4 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'naval-propulsion-plant', 'downscaling_factor': 1, 'yarin_gal_uci_split_indices': 12, 'max_dataset_size': 1000, 'standardize': True, 'select_timesteps': 'zero', 'temporal_downscaling_factor': 1, 'validation_ratio': 0.0}
INFO:root:After loading the datasets: mem (CPU python)=3236.51171875MB; mem (CPU total)=12378.3984375MB
INFO:root:###1 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'deterministic', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.51171875MB; mem (CPU total)=12378.484375MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421505.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3236.51171875MB; mem (CPU total)=12378.484375MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.79427
INFO:train:t_training_med: 0.79448
INFO:train:t_training_std: 0.00543
INFO:train:After finishing all epochs: mem (CPU python)=3236.51171875MB; mem (CPU total)=12408.87109375MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 4602.288s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 4.526s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00013
INFO:root:EnergyScoreTrain: 8e-05
INFO:root:CRPSTrain: 8e-05
INFO:root:Gaussian NLLTrain: -0.66531
INFO:root:CoverageTrain: 0.29783
INFO:root:QICETrain: 0.11136
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 4.394s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00014
INFO:root:EnergyScoreTest: 8e-05
INFO:root:CRPSTest: 8e-05
INFO:root:Gaussian NLLTest: 0.50168
INFO:root:CoverageTest: 0.27913
INFO:root:QICETest: 0.11507
INFO:root:After validation: mem (CPU python)=3236.5234375MB; mem (CPU total)=12409.54296875MB
INFO:root:###2 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'normal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.5234375MB; mem (CPU total)=12409.54296875MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421763.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3236.5234375MB; mem (CPU total)=12409.78515625MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.96623
INFO:train:t_training_med: 0.9651
INFO:train:t_training_std: 0.00702
INFO:train:After finishing all epochs: mem (CPU python)=3236.5234375MB; mem (CPU total)=12410.171875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5459.903s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 6.517s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00011
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -8.10476
INFO:root:CoverageTrain: 0.94088
INFO:root:QICETrain: 0.00638
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 6.207s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00012
INFO:root:EnergyScoreTest: 5e-05
INFO:root:CRPSTest: 5e-05
INFO:root:Gaussian NLLTest: -8.00014
INFO:root:CoverageTest: 0.91366
INFO:root:QICETest: 0.00835
INFO:root:After validation: mem (CPU python)=3236.5234375MB; mem (CPU total)=12410.28515625MB
INFO:root:###3 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'sample', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.5234375MB; mem (CPU total)=12410.28515625MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 421633.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3236.5234375MB; mem (CPU total)=12410.28515625MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.9459
INFO:train:t_training_med: 0.9448
INFO:train:t_training_std: 0.0055
INFO:train:After finishing all epochs: mem (CPU python)=3236.5234375MB; mem (CPU total)=12412.80859375MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5360.24s.
INFO:root:Emptying the cuda cache took 0.001s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 5.97s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00011
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -8.05693
INFO:root:CoverageTrain: 0.96006
INFO:root:QICETrain: 0.02008
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 5.65s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00013
INFO:root:EnergyScoreTest: 6e-05
INFO:root:CRPSTest: 6e-05
INFO:root:Gaussian NLLTest: -7.99198
INFO:root:CoverageTest: 0.94468
INFO:root:QICETest: 0.02015
INFO:root:After validation: mem (CPU python)=3236.5234375MB; mem (CPU total)=12413.01953125MB
INFO:root:###4 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'mixednormal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3236.5234375MB; mem (CPU total)=12413.01953125MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.0
INFO:train:NumberParameters: 522123.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3236.5234375MB; mem (CPU total)=12413.01953125MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 1.40212
INFO:train:t_training_med: 1.40147
INFO:train:t_training_std: 0.0088
INFO:train:After finishing all epochs: mem (CPU python)=3236.5234375MB; mem (CPU total)=14078.66015625MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 7641.495s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 8.847s.
INFO:root:MSETrain: 0.0
INFO:root:RMSETrain: 0.00011
INFO:root:EnergyScoreTrain: 5e-05
INFO:root:CRPSTrain: 5e-05
INFO:root:Gaussian NLLTrain: -8.1632
INFO:root:CoverageTrain: 0.91807
INFO:root:QICETrain: 0.0056
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 8.38s.
INFO:root:MSETest: 0.0
INFO:root:RMSETest: 0.00013
INFO:root:EnergyScoreTest: 5e-05
INFO:root:CRPSTest: 5e-05
INFO:root:Gaussian NLLTest: -8.10458
INFO:root:CoverageTest: 0.90863
INFO:root:QICETest: 0.01058
INFO:root:After validation: mem (CPU python)=3236.53125MB; mem (CPU total)=14077.21484375MB
