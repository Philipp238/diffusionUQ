INFO:root:Starting the logger.
INFO:root:Using device cuda.
INFO:root:Using 4 threads
INFO:root:: mem (CPU python)=596.671875MB; mem (CPU total)=15540.37890625MB
INFO:root:############### Starting experiment with config file configs_250714_CARD_sampling_and_epochs_likeCARD/kin8nm.ini ###############
INFO:root:###1 out of 3 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'kin8nm', 'downscaling_factor': 1, 'yarin_gal_uci_split_indices': 3, 'max_dataset_size': 1000, 'standardize': True, 'select_timesteps': 'zero', 'temporal_downscaling_factor': 1, 'validation_ratio': 0.0}
INFO:root:After loading the datasets: mem (CPU python)=596.671875MB; mem (CPU total)=15540.37890625MB
INFO:root:###1 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'deterministic', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=2119.4296875MB; mem (CPU total)=16827.62890625MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 418945.0
INFO:train:GPU memory allocated: 23068672
INFO:train:After setting up the model: mem (CPU python)=3148.7578125MB; mem (CPU total)=17683.42578125MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.47717
INFO:train:t_training_med: 0.47647
INFO:train:t_training_std: 0.00359
INFO:train:After finishing all epochs: mem (CPU python)=3162.09765625MB; mem (CPU total)=17747.328125MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 2860.653s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 3.182s.
INFO:root:MSETrain: 0.00157
INFO:root:RMSETrain: 0.03966
INFO:root:EnergyScoreTrain: 0.02175
INFO:root:CRPSTrain: 0.02158
INFO:root:Gaussian NLLTrain: -1.80747
INFO:root:CoverageTrain: 0.84023
INFO:root:QICETrain: 0.03038
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 3.058s.
INFO:root:MSETest: 0.00496
INFO:root:RMSETest: 0.0704
INFO:root:EnergyScoreTest: 0.0434
INFO:root:CRPSTest: 0.04323
INFO:root:Gaussian NLLTest: 1.79005
INFO:root:CoverageTest: 0.57875
INFO:root:QICETest: 0.07844
INFO:root:After validation: mem (CPU python)=3199.8359375MB; mem (CPU total)=17777.6328125MB
INFO:root:###2 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'normal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3199.8359375MB; mem (CPU total)=17777.6328125MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 419203.0
INFO:train:GPU memory allocated: 33554432
INFO:train:After setting up the model: mem (CPU python)=3199.8359375MB; mem (CPU total)=17777.625MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.62955
INFO:train:t_training_med: 0.62961
INFO:train:t_training_std: 0.0032
INFO:train:After finishing all epochs: mem (CPU python)=3200.609375MB; mem (CPU total)=17775.90625MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 3642.489s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 4.526s.
INFO:root:MSETrain: 0.00025
INFO:root:RMSETrain: 0.01588
INFO:root:EnergyScoreTrain: 0.0083
INFO:root:CRPSTrain: 0.00821
INFO:root:Gaussian NLLTrain: -2.78012
INFO:root:CoverageTrain: 0.93042
INFO:root:QICETrain: 0.00671
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 4.308s.
INFO:root:MSETest: 0.00613
INFO:root:RMSETest: 0.07829
INFO:root:EnergyScoreTest: 0.05449
INFO:root:CRPSTest: 0.05441
INFO:root:Gaussian NLLTest: 13.21433
INFO:root:CoverageTest: 0.28083
INFO:root:QICETest: 0.1219
INFO:root:After validation: mem (CPU python)=3201.02734375MB; mem (CPU total)=17775.796875MB
INFO:root:###3 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'sample', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3201.02734375MB; mem (CPU total)=17776.1015625MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 419073.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3201.02734375MB; mem (CPU total)=17776.04296875MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.65812
INFO:train:t_training_med: 0.6583
INFO:train:t_training_std: 0.00568
INFO:train:After finishing all epochs: mem (CPU python)=3202.97265625MB; mem (CPU total)=17782.3515625MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 3823.713s.
INFO:root:Emptying the cuda cache took 0.001s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 5.157s.
INFO:root:MSETrain: 0.00146
INFO:root:RMSETrain: 0.03827
INFO:root:EnergyScoreTrain: 0.02013
INFO:root:CRPSTrain: 0.01994
INFO:root:Gaussian NLLTrain: -1.95208
INFO:root:CoverageTrain: 0.92825
INFO:root:QICETrain: 0.00676
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 3.808s.
INFO:root:MSETest: 0.00554
INFO:root:RMSETest: 0.07446
INFO:root:EnergyScoreTest: 0.04498
INFO:root:CRPSTest: 0.04478
INFO:root:Gaussian NLLTest: 0.23216
INFO:root:CoverageTest: 0.62149
INFO:root:QICETest: 0.06403
INFO:root:After validation: mem (CPU python)=3203.0234375MB; mem (CPU total)=17781.55859375MB
INFO:root:###4 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'mixednormal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3203.03125MB; mem (CPU total)=17781.55859375MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 519563.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3203.03125MB; mem (CPU total)=17782.109375MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.96814
INFO:train:t_training_med: 0.9678
INFO:train:t_training_std: 0.00774
INFO:train:After finishing all epochs: mem (CPU python)=3204.34765625MB; mem (CPU total)=17781.96875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5359.311s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 7.243s.
INFO:root:MSETrain: 0.00028
INFO:root:RMSETrain: 0.01667
INFO:root:EnergyScoreTrain: 0.00874
INFO:root:CRPSTrain: 0.00865
INFO:root:Gaussian NLLTrain: -2.73325
INFO:root:CoverageTrain: 0.94059
INFO:root:QICETrain: 0.01506
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 5.865s.
INFO:root:MSETest: 0.00628
INFO:root:RMSETest: 0.07923
INFO:root:EnergyScoreTest: 0.05304
INFO:root:CRPSTest: 0.05295
INFO:root:Gaussian NLLTest: 11.4247
INFO:root:CoverageTest: 0.32479
INFO:root:QICETest: 0.11556
INFO:root:After validation: mem (CPU python)=3204.85546875MB; mem (CPU total)=17782.1171875MB
INFO:root:###2 out of 3 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'kin8nm', 'downscaling_factor': 1, 'yarin_gal_uci_split_indices': 4, 'max_dataset_size': 1000, 'standardize': True, 'select_timesteps': 'zero', 'temporal_downscaling_factor': 1, 'validation_ratio': 0.0}
INFO:root:After loading the datasets: mem (CPU python)=3204.85546875MB; mem (CPU total)=17782.1171875MB
INFO:root:###1 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'deterministic', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3204.85546875MB; mem (CPU total)=17782.16015625MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 418945.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3204.85546875MB; mem (CPU total)=17782.16015625MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.47029
INFO:train:t_training_med: 0.46963
INFO:train:t_training_std: 0.00269
INFO:train:After finishing all epochs: mem (CPU python)=3204.85546875MB; mem (CPU total)=17784.33984375MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 2814.504s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 3.095s.
INFO:root:MSETrain: 0.00134
INFO:root:RMSETrain: 0.03655
INFO:root:EnergyScoreTrain: 0.01992
INFO:root:CRPSTrain: 0.01978
INFO:root:Gaussian NLLTrain: -1.87935
INFO:root:CoverageTrain: 0.82748
INFO:root:QICETrain: 0.03205
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 2.994s.
INFO:root:MSETest: 0.00559
INFO:root:RMSETest: 0.07474
INFO:root:EnergyScoreTest: 0.04676
INFO:root:CRPSTest: 0.04661
INFO:root:Gaussian NLLTest: 3.24412
INFO:root:CoverageTest: 0.51282
INFO:root:QICETest: 0.08161
INFO:root:After validation: mem (CPU python)=3207.5234375MB; mem (CPU total)=17787.0390625MB
INFO:root:###2 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'normal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3207.5234375MB; mem (CPU total)=17787.0390625MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 419203.0
INFO:train:GPU memory allocated: 33554432
INFO:train:After setting up the model: mem (CPU python)=3207.5234375MB; mem (CPU total)=17787.0390625MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.61476
INFO:train:t_training_med: 0.61487
INFO:train:t_training_std: 0.00336
INFO:train:After finishing all epochs: mem (CPU python)=3207.5234375MB; mem (CPU total)=17786.55078125MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 3549.172s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 4.393s.
INFO:root:MSETrain: 0.00025
INFO:root:RMSETrain: 0.01566
INFO:root:EnergyScoreTrain: 0.00816
INFO:root:CRPSTrain: 0.00808
INFO:root:Gaussian NLLTrain: -2.79716
INFO:root:CoverageTrain: 0.92907
INFO:root:QICETrain: 0.0078
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 4.185s.
INFO:root:MSETest: 0.00702
INFO:root:RMSETest: 0.08379
INFO:root:EnergyScoreTest: 0.05788
INFO:root:CRPSTest: 0.05779
INFO:root:Gaussian NLLTest: 14.83886
INFO:root:CoverageTest: 0.26374
INFO:root:QICETest: 0.12459
INFO:root:After validation: mem (CPU python)=3210.30859375MB; mem (CPU total)=17789.9921875MB
INFO:root:###3 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'sample', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3210.30859375MB; mem (CPU total)=17789.9921875MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 419073.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3210.30859375MB; mem (CPU total)=17789.9921875MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.64447
INFO:train:t_training_med: 0.6445
INFO:train:t_training_std: 0.0033
INFO:train:After finishing all epochs: mem (CPU python)=3210.3125MB; mem (CPU total)=17792.3671875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 3737.107s.
INFO:root:Emptying the cuda cache took 0.001s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 5.162s.
INFO:root:MSETrain: 0.00085
INFO:root:RMSETrain: 0.02917
INFO:root:EnergyScoreTrain: 0.01531
INFO:root:CRPSTrain: 0.01515
INFO:root:Gaussian NLLTrain: -2.19454
INFO:root:CoverageTrain: 0.93178
INFO:root:QICETrain: 0.01295
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 3.862s.
INFO:root:MSETest: 0.00629
INFO:root:RMSETest: 0.0793
INFO:root:EnergyScoreTest: 0.05052
INFO:root:CRPSTest: 0.05037
INFO:root:Gaussian NLLTest: 2.01444
INFO:root:CoverageTest: 0.50061
INFO:root:QICETest: 0.09138
INFO:root:After validation: mem (CPU python)=3210.55078125MB; mem (CPU total)=17792.5234375MB
INFO:root:###4 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'mixednormal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3210.55078125MB; mem (CPU total)=17792.5234375MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 519563.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3210.55078125MB; mem (CPU total)=17792.5234375MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.96877
INFO:train:t_training_med: 0.96852
INFO:train:t_training_std: 0.00864
INFO:train:After finishing all epochs: mem (CPU python)=3210.56640625MB; mem (CPU total)=17793.75390625MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5363.046s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 6.507s.
INFO:root:MSETrain: 0.00029
INFO:root:RMSETrain: 0.01713
INFO:root:EnergyScoreTrain: 0.00902
INFO:root:CRPSTrain: 0.00892
INFO:root:Gaussian NLLTrain: -2.71429
INFO:root:CoverageTrain: 0.95226
INFO:root:QICETrain: 0.01937
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 5.791s.
INFO:root:MSETest: 0.00633
INFO:root:RMSETest: 0.07956
INFO:root:EnergyScoreTest: 0.05297
INFO:root:CRPSTest: 0.05287
INFO:root:Gaussian NLLTest: 8.73813
INFO:root:CoverageTest: 0.36386
INFO:root:QICETest: 0.11018
INFO:root:After validation: mem (CPU python)=3210.6015625MB; mem (CPU total)=17793.609375MB
INFO:root:###3 out of 3 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'kin8nm', 'downscaling_factor': 1, 'yarin_gal_uci_split_indices': 5, 'max_dataset_size': 1000, 'standardize': True, 'select_timesteps': 'zero', 'temporal_downscaling_factor': 1, 'validation_ratio': 0.0}
INFO:root:After loading the datasets: mem (CPU python)=3210.6015625MB; mem (CPU total)=17793.609375MB
INFO:root:###1 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'deterministic', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3210.6015625MB; mem (CPU total)=17793.609375MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 418945.0
INFO:train:GPU memory allocated: 27262976
INFO:train:After setting up the model: mem (CPU python)=3210.6015625MB; mem (CPU total)=17793.609375MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.46972
INFO:train:t_training_med: 0.46896
INFO:train:t_training_std: 0.00288
INFO:train:After finishing all epochs: mem (CPU python)=3210.6015625MB; mem (CPU total)=17742.0234375MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 2811.445s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 3.069s.
INFO:root:MSETrain: 0.00121
INFO:root:RMSETrain: 0.03476
INFO:root:EnergyScoreTrain: 0.01868
INFO:root:CRPSTrain: 0.01853
INFO:root:Gaussian NLLTrain: -1.97418
INFO:root:CoverageTrain: 0.86668
INFO:root:QICETrain: 0.02391
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 2.958s.
INFO:root:MSETest: 0.00633
INFO:root:RMSETest: 0.07955
INFO:root:EnergyScoreTest: 0.05035
INFO:root:CRPSTest: 0.0502
INFO:root:Gaussian NLLTest: 6.95485
INFO:root:CoverageTest: 0.52015
INFO:root:QICETest: 0.0865
INFO:root:After validation: mem (CPU python)=3210.6015625MB; mem (CPU total)=17741.890625MB
INFO:root:###2 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'normal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3210.6015625MB; mem (CPU total)=17741.890625MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 419203.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3210.6015625MB; mem (CPU total)=17741.890625MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.61441
INFO:train:t_training_med: 0.61421
INFO:train:t_training_std: 0.00525
INFO:train:After finishing all epochs: mem (CPU python)=3210.6015625MB; mem (CPU total)=17791.5546875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 3554.337s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 4.371s.
INFO:root:MSETrain: 0.00025
INFO:root:RMSETrain: 0.01576
INFO:root:EnergyScoreTrain: 0.0083
INFO:root:CRPSTrain: 0.00821
INFO:root:Gaussian NLLTrain: -2.77364
INFO:root:CoverageTrain: 0.96148
INFO:root:QICETrain: 0.02733
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 4.184s.
INFO:root:MSETest: 0.00698
INFO:root:RMSETest: 0.08353
INFO:root:EnergyScoreTest: 0.05666
INFO:root:CRPSTest: 0.05657
INFO:root:Gaussian NLLTest: 9.57104
INFO:root:CoverageTest: 0.32479
INFO:root:QICETest: 0.11604
INFO:root:After validation: mem (CPU python)=3210.6015625MB; mem (CPU total)=17792.44921875MB
INFO:root:###3 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'sample', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3210.6015625MB; mem (CPU total)=17792.44921875MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 419073.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3210.6015625MB; mem (CPU total)=17792.44921875MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.64691
INFO:train:t_training_med: 0.64585
INFO:train:t_training_std: 0.00801
INFO:train:After finishing all epochs: mem (CPU python)=3210.6015625MB; mem (CPU total)=17791.9921875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 3751.74s.
INFO:root:Emptying the cuda cache took 0.001s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 5.148s.
INFO:root:MSETrain: 0.00086
INFO:root:RMSETrain: 0.02934
INFO:root:EnergyScoreTrain: 0.0152
INFO:root:CRPSTrain: 0.01505
INFO:root:Gaussian NLLTrain: -2.20628
INFO:root:CoverageTrain: 0.92879
INFO:root:QICETrain: 0.01076
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 3.844s.
INFO:root:MSETest: 0.00645
INFO:root:RMSETest: 0.08031
INFO:root:EnergyScoreTest: 0.05071
INFO:root:CRPSTest: 0.05055
INFO:root:Gaussian NLLTest: 2.25046
INFO:root:CoverageTest: 0.51038
INFO:root:QICETest: 0.08967
INFO:root:After validation: mem (CPU python)=3210.6171875MB; mem (CPU total)=17791.93359375MB
INFO:root:###4 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'MLP', 'uncertainty_quantification': 'diffusion', 'report_every': 50, 'seed': 1234, 'distributed_training': False, 'backbone': 'CARD', 'batch_size': 64, 'batch_accumulation': 1, 'eval_batch_size': 16384, 'n_epochs': 5000, 'early_stopping': 1000, 'init': 'default', 'learning_rate': 0.001, 'warmup_lr': 0, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'n_val_samples': 10, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'n_timesteps': 50, 'beta_endpoints': (0.001, 0.35), 'distributional_method': 'mixednormal', 'loss': 'crps', 'closed_form': True, 'concat_condition_diffusion': True, 'evaluate': True, 'val_only': False, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': False, 'ddim_churn': 1.0, 'noise_schedule': 'linear', 'regressor': 'orig_CARD_pretrain', 'n_components': 3, 'gamma': 5.0, 'rank': 10, 'mvnormal_method': 'lora', 'n_train_samples': 10, 'metrics_plots': False}
INFO:root:Using pre-trained regressor from the CARD repo
INFO:root:After creating the dataloaders: mem (CPU python)=3210.6171875MB; mem (CPU total)=17791.93359375MB
INFO:root:Performance of pre-trained regressor on test set: RMSE=0.07
INFO:train:NumberParameters: 519563.0
INFO:train:GPU memory allocated: 25165824
INFO:train:After setting up the model: mem (CPU python)=3210.6171875MB; mem (CPU total)=17791.93359375MB
INFO:train:Training starts now.
INFO:train:t_training_avg: 0.96711
INFO:train:t_training_med: 0.96688
INFO:train:t_training_std: 0.00795
INFO:train:After finishing all epochs: mem (CPU python)=3210.6171875MB; mem (CPU total)=17793.421875MB
INFO:train:Proceeding with diffusion model after 5000 epochs of training
INFO:root:Training the model took 5355.677s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification diffusion
INFO:root:Evaluating the model on Train data.
INFO:root:Evaluating the model on Train data took 7.148s.
INFO:root:MSETrain: 0.00034
INFO:root:RMSETrain: 0.01847
INFO:root:EnergyScoreTrain: 0.00982
INFO:root:CRPSTrain: 0.00972
INFO:root:Gaussian NLLTrain: -2.63078
INFO:root:CoverageTrain: 0.9486
INFO:root:QICETrain: 0.0146
INFO:root:Evaluating the model on Test data.
INFO:root:Evaluating the model on Test data took 5.836s.
INFO:root:MSETest: 0.00738
INFO:root:RMSETest: 0.08592
INFO:root:EnergyScoreTest: 0.05727
INFO:root:CRPSTest: 0.05716
INFO:root:Gaussian NLLTest: 9.34501
INFO:root:CoverageTest: 0.3663
INFO:root:QICETest: 0.11336
INFO:root:After validation: mem (CPU python)=3210.68359375MB; mem (CPU total)=17792.8046875MB
