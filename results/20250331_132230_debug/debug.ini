[META]
results_path = results/
data_path = data/
experiment_name = debug
; only_validate = filename

[TRAININGPARAMETERS]
report_every = 100
seed = [1234]
model = 'MLP'
# 'diffusion', 'dropout', 'scoring-rule-dropout', 'scoring-rule-reparam', 'deep-ensemble', 'deterministic', 'laplace', 
uncertainty_quantification = ['dropout']  
batch_size =  [1024]
n_epochs = 10000
early_stopping = 500
init = 'default' # he, xavier, default
learning_rate = 0.001
lr_schedule = 'step' # 'no', 'step'
optimizer = 'adam'
gradient_clipping = 1
; layer_normalization = True
data_loader_pin_memory = False 
data_loader_num_workers = [0]
distributed_training = False
alpha = 0.05
n_samples_uq = 100
weight_decay = 0.01
### Model Parameters
dropout = [0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.9, 0.99]
; dropout = [0.3, 0.9, 0.99]
hidden_dim = 128
n_layers = 3
### Diffusion Parameters
concat_condition_diffusion = False


[DATAPARAMETERS]
; housing_prices, x-squared
dataset_name = ['housing_prices']
max_dataset_size = 1024
standardize = True