[META]
results_path = results/
data_path = data/
experiment_name = debug
; only_validate = 20250611_173020_debug

[TRAININGPARAMETERS]
report_every = 50
seed = [1234]
model = 'UNet'
# 'diffusion', 'dropout', 'scoring-rule-dropout', 'scoring-rule-reparam', 'deep-ensemble', 'deterministic', 'laplace', 
uncertainty_quantification = ['diffusion']  
backbone = ["default"] # "default", "CARD"
batch_size =  [128]
eval_batch_size = 512
n_epochs = 1000
early_stopping = 100
init = 'default' # he, xavier, default
learning_rate = 0.0001
lr_schedule = 'step' # 'no', 'step'
optimizer = 'adam'
gradient_clipping = 1
distributed_training = False
alpha = 0.05
n_samples_uq = 100
weight_decay = 0.0
### Model Parameters
dropout = [0.1]
hidden_dim = [64]
n_layers = [2]
### Diffusion Parameters
n_timesteps = [50]
distributional_method = ["mvnormal"]#["normal", "mixednormal","deterministic", "sample"] # "deterministic", "normal", "mixednormal", "sample" 
loss = ["kernel"] # crps, kernel
mvnormal_method = ["lora"] # "lora", "cholesky"
concat_condition_diffusion = True
evaluate = True
conditional_free_guidance_training=False
ddim_sigma = 1.0
noise_schedule = 'linear'

[DATAPARAMETERS]
dataset_name = ['1D_Burgers']# '1D_Advection', 
downscaling_factor = 4
standardize = True