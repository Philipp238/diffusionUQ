INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=520.99609375MB; mem (CPU total)=5610.51953125MB
INFO:root:############### Starting experiment with config file debug.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'concrete', 'max_dataset_size': 100000, 'standardize': True}
INFO:root:After loading the datasets: mem (CPU python)=528.8671875MB; mem (CPU total)=5616.34765625MB
INFO:root:###1 out of 1 training parameter combinations ###
INFO:root:Training parameters: {'report_every': 5, 'seed': 1234, 'model': 'MLP', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'eval_batch_size': 16384, 'n_epochs': 10000, 'early_stopping': 50, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'concat_condition_diffusion': True, 'evaluate': False, 'regressor': None}
INFO:root:After creating the dataloaders: mem (CPU python)=530.37890625MB; mem (CPU total)=5616.34765625MB
INFO:root:NumberParameters: 8961
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=624.75MB; mem (CPU total)=5699.34375MB
INFO:root:Training starts now.
INFO:root:[    5] Training loss: 0.94817873, Validation loss: 0.98152006, Validation loss EMA: 0.97265995
INFO:root:[   10] Training loss: 0.91347806, Validation loss: 0.93787569, Validation loss EMA: 0.91965938
INFO:root:[   15] Training loss: 0.86561339, Validation loss: 0.85385489, Validation loss EMA: 0.84067571
INFO:root:[   20] Training loss: 0.80043787, Validation loss: 0.77792180, Validation loss EMA: 0.75046962
INFO:root:[   25] Training loss: 0.73451799, Validation loss: 0.67649400, Validation loss EMA: 0.66839212
INFO:root:[   30] Training loss: 0.67940345, Validation loss: 0.62764764, Validation loss EMA: 0.60417295
INFO:root:[   35] Training loss: 0.64257330, Validation loss: 0.60532749, Validation loss EMA: 0.55704099
INFO:root:[   40] Training loss: 0.61196032, Validation loss: 0.56916738, Validation loss EMA: 0.52046907
INFO:root:[   45] Training loss: 0.57535779, Validation loss: 0.52581233, Validation loss EMA: 0.48148698
INFO:root:[   50] Training loss: 0.54598740, Validation loss: 0.45312086, Validation loss EMA: 0.45307967
INFO:root:[   55] Training loss: 0.52052616, Validation loss: 0.44923580, Validation loss EMA: 0.42185077
INFO:root:[   60] Training loss: 0.49360535, Validation loss: 0.44119921, Validation loss EMA: 0.39392549
INFO:root:[   65] Training loss: 0.47183502, Validation loss: 0.39028731, Validation loss EMA: 0.36990014
INFO:root:[   70] Training loss: 0.44045944, Validation loss: 0.39787915, Validation loss EMA: 0.35035080
INFO:root:[   75] Training loss: 0.42653938, Validation loss: 0.34506509, Validation loss EMA: 0.33127397
INFO:root:[   80] Training loss: 0.40310118, Validation loss: 0.32642847, Validation loss EMA: 0.31842312
INFO:root:[   85] Training loss: 0.38905792, Validation loss: 0.31970653, Validation loss EMA: 0.31017244
INFO:root:[   90] Training loss: 0.38526023, Validation loss: 0.32153797, Validation loss EMA: 0.30432561
INFO:root:[   95] Training loss: 0.36331382, Validation loss: 0.30619368, Validation loss EMA: 0.29940486
INFO:root:[  100] Training loss: 0.35713851, Validation loss: 0.29275033, Validation loss EMA: 0.29534450
INFO:root:[  105] Training loss: 0.35448702, Validation loss: 0.32277337, Validation loss EMA: 0.29433545
INFO:root:[  110] Training loss: 0.34548451, Validation loss: 0.29086110, Validation loss EMA: 0.28994232
INFO:root:[  115] Training loss: 0.33970058, Validation loss: 0.31136605, Validation loss EMA: 0.28772664
INFO:root:[  120] Training loss: 0.33327103, Validation loss: 0.27713716, Validation loss EMA: 0.28245538
INFO:root:[  125] Training loss: 0.32926306, Validation loss: 0.32919025, Validation loss EMA: 0.28508455
INFO:root:[  130] Training loss: 0.32655546, Validation loss: 0.31426737, Validation loss EMA: 0.27604404
INFO:root:[  135] Training loss: 0.32263882, Validation loss: 0.30485862, Validation loss EMA: 0.27213088
INFO:root:[  140] Training loss: 0.31734226, Validation loss: 0.30126604, Validation loss EMA: 0.26964238
INFO:root:[  145] Training loss: 0.31365853, Validation loss: 0.31168276, Validation loss EMA: 0.27960503
INFO:root:[  150] Training loss: 0.30656316, Validation loss: 0.28709689, Validation loss EMA: 0.26431966
INFO:root:[  155] Training loss: 0.30316245, Validation loss: 0.30897844, Validation loss EMA: 0.26041993
INFO:root:[  160] Training loss: 0.29193799, Validation loss: 0.28205988, Validation loss EMA: 0.25995705
INFO:root:[  165] Training loss: 0.29220072, Validation loss: 0.29384863, Validation loss EMA: 0.25850546
INFO:root:EP 169: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=795.1015625MB; mem (CPU total)=5826.6171875MB
INFO:root:Training the model took 18.22s.
INFO:root:Emptying the cuda cache took 0.0s.
