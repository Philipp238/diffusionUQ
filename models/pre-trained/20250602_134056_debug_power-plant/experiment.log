INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=536.90625MB; mem (CPU total)=72946.56640625MB
INFO:root:############### Starting experiment with config file debug_power-plant.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'power-plant', 'yarin_gal_uci_split_indices': 0, 'max_dataset_size': 1000, 'standardize': True}
INFO:root:After loading the datasets: mem (CPU python)=543.5625MB; mem (CPU total)=72608.23046875MB
INFO:root:###1 out of 1 training parameter combinations ###
INFO:root:Training parameters: {'report_every': 5, 'seed': 1234, 'model': 'MLP', 'uncertainty_quantification': 'dropout', 'backbone': 'default', 'batch_size': 64, 'eval_batch_size': 16384, 'n_epochs': 1000, 'early_stopping': 50, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'distributional_method': 'mixednormal', 'concat_condition_diffusion': True, 'evaluate': True, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': True, 'regressor': None}
INFO:root:Using split-0 for UCI dataset power-plant
INFO:root:After creating the dataloaders: mem (CPU python)=543.81640625MB; mem (CPU total)=72488.3125MB
INFO:root:NumberParameters: 8705
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2143.484375MB; mem (CPU total)=70304.75MB
INFO:root:Training starts now.
INFO:root:[    5] Training loss: 0.18256690, Validation loss: 0.07471287, Validation loss EMA: 0.06306786
INFO:root:[   10] Training loss: 0.07127369, Validation loss: 0.07136146, Validation loss EMA: 0.06101029
INFO:root:[   15] Training loss: 0.06933175, Validation loss: 0.06996089, Validation loss EMA: 0.06030118
INFO:root:[   20] Training loss: 0.06820635, Validation loss: 0.06886396, Validation loss EMA: 0.05978654
INFO:root:[   25] Training loss: 0.06694336, Validation loss: 0.06794491, Validation loss EMA: 0.05921586
INFO:root:[   30] Training loss: 0.06613217, Validation loss: 0.06667132, Validation loss EMA: 0.05868121
INFO:root:[   35] Training loss: 0.06544048, Validation loss: 0.06552317, Validation loss EMA: 0.05829193
INFO:root:[   40] Training loss: 0.06532200, Validation loss: 0.06483101, Validation loss EMA: 0.05794827
INFO:root:[   45] Training loss: 0.06479851, Validation loss: 0.06635798, Validation loss EMA: 0.05763769
INFO:root:[   50] Training loss: 0.06444099, Validation loss: 0.06503353, Validation loss EMA: 0.05734292
INFO:root:[   55] Training loss: 0.06343851, Validation loss: 0.06389362, Validation loss EMA: 0.05704619
INFO:root:[   60] Training loss: 0.06351477, Validation loss: 0.06482252, Validation loss EMA: 0.05682311
INFO:root:[   65] Training loss: 0.06295634, Validation loss: 0.06381470, Validation loss EMA: 0.05658093
INFO:root:[   70] Training loss: 0.06292049, Validation loss: 0.06397493, Validation loss EMA: 0.05632291
INFO:root:[   75] Training loss: 0.06308430, Validation loss: 0.06404052, Validation loss EMA: 0.05619953
INFO:root:[   80] Training loss: 0.06258804, Validation loss: 0.06336275, Validation loss EMA: 0.05603718
INFO:root:[   85] Training loss: 0.06254984, Validation loss: 0.06260910, Validation loss EMA: 0.05588650
INFO:root:[   90] Training loss: 0.06176819, Validation loss: 0.06310032, Validation loss EMA: 0.05579225
INFO:root:[   95] Training loss: 0.06191404, Validation loss: 0.06194621, Validation loss EMA: 0.05570081
INFO:root:[  100] Training loss: 0.06141383, Validation loss: 0.06253747, Validation loss EMA: 0.05542036
INFO:root:[  105] Training loss: 0.06126539, Validation loss: 0.06232633, Validation loss EMA: 0.05534279
INFO:root:[  110] Training loss: 0.06099009, Validation loss: 0.06206587, Validation loss EMA: 0.05530039
INFO:root:[  115] Training loss: 0.06124963, Validation loss: 0.06152136, Validation loss EMA: 0.05519556
INFO:root:[  120] Training loss: 0.06122954, Validation loss: 0.06141139, Validation loss EMA: 0.05512393
INFO:root:[  125] Training loss: 0.06097487, Validation loss: 0.06130163, Validation loss EMA: 0.05492165
INFO:root:[  130] Training loss: 0.06063401, Validation loss: 0.06117639, Validation loss EMA: 0.05489030
INFO:root:[  135] Training loss: 0.06059137, Validation loss: 0.06226208, Validation loss EMA: 0.05482888
INFO:root:[  140] Training loss: 0.06037098, Validation loss: 0.06026053, Validation loss EMA: 0.05470081
INFO:root:[  145] Training loss: 0.06026091, Validation loss: 0.06074220, Validation loss EMA: 0.05460707
INFO:root:[  150] Training loss: 0.05997449, Validation loss: 0.06144996, Validation loss EMA: 0.05448433
INFO:root:[  155] Training loss: 0.06006654, Validation loss: 0.06102445, Validation loss EMA: 0.05435516
INFO:root:[  160] Training loss: 0.06002298, Validation loss: 0.06035719, Validation loss EMA: 0.05433136
INFO:root:[  165] Training loss: 0.06036078, Validation loss: 0.06137691, Validation loss EMA: 0.05450255
INFO:root:[  170] Training loss: 0.05921782, Validation loss: 0.06099215, Validation loss EMA: 0.05416910
INFO:root:[  175] Training loss: 0.05950211, Validation loss: 0.06109245, Validation loss EMA: 0.05399079
INFO:root:[  180] Training loss: 0.05963738, Validation loss: 0.06017761, Validation loss EMA: 0.05404149
INFO:root:[  185] Training loss: 0.05929316, Validation loss: 0.06060893, Validation loss EMA: 0.05392203
INFO:root:[  190] Training loss: 0.05930647, Validation loss: 0.06030844, Validation loss EMA: 0.05382281
INFO:root:[  195] Training loss: 0.05902089, Validation loss: 0.05928497, Validation loss EMA: 0.05376483
INFO:root:[  200] Training loss: 0.05921877, Validation loss: 0.06069241, Validation loss EMA: 0.05366036
INFO:root:[  205] Training loss: 0.05922888, Validation loss: 0.05977937, Validation loss EMA: 0.05359573
INFO:root:[  210] Training loss: 0.05920225, Validation loss: 0.06069440, Validation loss EMA: 0.05351620
INFO:root:[  215] Training loss: 0.05868412, Validation loss: 0.05959781, Validation loss EMA: 0.05352503
INFO:root:[  220] Training loss: 0.05879266, Validation loss: 0.06023560, Validation loss EMA: 0.05347098
INFO:root:[  225] Training loss: 0.05878481, Validation loss: 0.05953746, Validation loss EMA: 0.05342276
INFO:root:[  230] Training loss: 0.05844383, Validation loss: 0.05948083, Validation loss EMA: 0.05336291
INFO:root:[  235] Training loss: 0.05830343, Validation loss: 0.05935338, Validation loss EMA: 0.05335550
INFO:root:[  240] Training loss: 0.05871361, Validation loss: 0.05918473, Validation loss EMA: 0.05320903
INFO:root:[  245] Training loss: 0.05804973, Validation loss: 0.06011103, Validation loss EMA: 0.05301420
INFO:root:[  250] Training loss: 0.05822970, Validation loss: 0.06027976, Validation loss EMA: 0.05294594
INFO:root:[  255] Training loss: 0.05867755, Validation loss: 0.05898944, Validation loss EMA: 0.05308875
INFO:root:[  260] Training loss: 0.05820386, Validation loss: 0.05930877, Validation loss EMA: 0.05302640
INFO:root:[  265] Training loss: 0.05787180, Validation loss: 0.05807496, Validation loss EMA: 0.05293259
INFO:root:[  270] Training loss: 0.05808194, Validation loss: 0.05921185, Validation loss EMA: 0.05280092
INFO:root:[  275] Training loss: 0.05781289, Validation loss: 0.05906420, Validation loss EMA: 0.05284503
INFO:root:[  280] Training loss: 0.05797598, Validation loss: 0.05794502, Validation loss EMA: 0.05284415
INFO:root:[  285] Training loss: 0.05773416, Validation loss: 0.05907150, Validation loss EMA: 0.05274532
INFO:root:[  290] Training loss: 0.05833803, Validation loss: 0.05882766, Validation loss EMA: 0.05285268
INFO:root:[  295] Training loss: 0.05777330, Validation loss: 0.05862649, Validation loss EMA: 0.05265977
INFO:root:[  300] Training loss: 0.05803999, Validation loss: 0.05903165, Validation loss EMA: 0.05261698
INFO:root:[  305] Training loss: 0.05730171, Validation loss: 0.05839112, Validation loss EMA: 0.05280342
INFO:root:[  310] Training loss: 0.05763671, Validation loss: 0.05799629, Validation loss EMA: 0.05274734
INFO:root:[  315] Training loss: 0.05758649, Validation loss: 0.05826569, Validation loss EMA: 0.05256290
INFO:root:[  320] Training loss: 0.05738980, Validation loss: 0.05772810, Validation loss EMA: 0.05233641
INFO:root:[  325] Training loss: 0.05769599, Validation loss: 0.05825087, Validation loss EMA: 0.05262592
INFO:root:[  330] Training loss: 0.05733305, Validation loss: 0.05886475, Validation loss EMA: 0.05241454
INFO:root:[  335] Training loss: 0.05721129, Validation loss: 0.05903891, Validation loss EMA: 0.05242460
INFO:root:[  340] Training loss: 0.05741194, Validation loss: 0.05909228, Validation loss EMA: 0.05225370
INFO:root:[  345] Training loss: 0.05724336, Validation loss: 0.05775324, Validation loss EMA: 0.05237205
INFO:root:[  350] Training loss: 0.05735520, Validation loss: 0.05778419, Validation loss EMA: 0.05230377
INFO:root:[  355] Training loss: 0.05736817, Validation loss: 0.05817237, Validation loss EMA: 0.05230327
INFO:root:[  360] Training loss: 0.05721504, Validation loss: 0.05737823, Validation loss EMA: 0.05230183
INFO:root:[  365] Training loss: 0.05689432, Validation loss: 0.05794828, Validation loss EMA: 0.05215191
INFO:root:[  370] Training loss: 0.05735877, Validation loss: 0.05805247, Validation loss EMA: 0.05217491
INFO:root:[  375] Training loss: 0.05703457, Validation loss: 0.05773626, Validation loss EMA: 0.05215187
INFO:root:[  380] Training loss: 0.05690876, Validation loss: 0.05831452, Validation loss EMA: 0.05206554
INFO:root:[  385] Training loss: 0.05638742, Validation loss: 0.05832508, Validation loss EMA: 0.05191679
INFO:root:[  390] Training loss: 0.05668939, Validation loss: 0.05758599, Validation loss EMA: 0.05217136
INFO:root:[  395] Training loss: 0.05693357, Validation loss: 0.05816266, Validation loss EMA: 0.05188304
INFO:root:[  400] Training loss: 0.05679930, Validation loss: 0.05794811, Validation loss EMA: 0.05192282
INFO:root:[  405] Training loss: 0.05662232, Validation loss: 0.05703253, Validation loss EMA: 0.05193826
INFO:root:[  410] Training loss: 0.05650291, Validation loss: 0.05733369, Validation loss EMA: 0.05193057
INFO:root:[  415] Training loss: 0.05638101, Validation loss: 0.05767398, Validation loss EMA: 0.05188818
INFO:root:[  420] Training loss: 0.05648530, Validation loss: 0.05677469, Validation loss EMA: 0.05201969
INFO:root:[  425] Training loss: 0.05660299, Validation loss: 0.05869436, Validation loss EMA: 0.05200235
INFO:root:[  430] Training loss: 0.05673280, Validation loss: 0.05757252, Validation loss EMA: 0.05189744
INFO:root:[  435] Training loss: 0.05609982, Validation loss: 0.05814010, Validation loss EMA: 0.05184125
INFO:root:[  440] Training loss: 0.05632314, Validation loss: 0.05611149, Validation loss EMA: 0.05188382
INFO:root:[  445] Training loss: 0.05623722, Validation loss: 0.05712476, Validation loss EMA: 0.05171471
INFO:root:[  450] Training loss: 0.05614267, Validation loss: 0.05752426, Validation loss EMA: 0.05172817
INFO:root:[  455] Training loss: 0.05637435, Validation loss: 0.05753733, Validation loss EMA: 0.05170474
INFO:root:[  460] Training loss: 0.05631878, Validation loss: 0.05658869, Validation loss EMA: 0.05183508
INFO:root:[  465] Training loss: 0.05625902, Validation loss: 0.05677899, Validation loss EMA: 0.05163329
INFO:root:[  470] Training loss: 0.05644649, Validation loss: 0.05744720, Validation loss EMA: 0.05175229
INFO:root:[  475] Training loss: 0.05630248, Validation loss: 0.05751175, Validation loss EMA: 0.05191590
INFO:root:[  480] Training loss: 0.05622063, Validation loss: 0.05722108, Validation loss EMA: 0.05174631
INFO:root:[  485] Training loss: 0.05591711, Validation loss: 0.05638440, Validation loss EMA: 0.05165415
INFO:root:EP 489: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=3191.03515625MB; mem (CPU total)=70467.01953125MB
INFO:root:Training the model took 192.823s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 14.29611
INFO:root:RMSETrain: 3.78102
INFO:root:EnergyScoreTrain: 2.32394
INFO:root:CRPSTrain: 2.31644
INFO:root:Gaussian NLLTrain: 6.03261
INFO:root:CoverageTrain: 0.50482
INFO:root:QICETrain: 0.08802
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 14.59386
INFO:root:RMSEValidation: 3.82019
INFO:root:EnergyScoreValidation: 2.33672
INFO:root:CRPSValidation: 2.32922
INFO:root:Gaussian NLLValidation: 6.09341
INFO:root:CoverageValidation: 0.50861
INFO:root:QICEValidation: 0.08833
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 16.88417
INFO:root:RMSETest: 4.10903
INFO:root:EnergyScoreTest: 2.46552
INFO:root:CRPSTest: 2.45778
INFO:root:Gaussian NLLTest: 6.67661
INFO:root:CoverageTest: 0.50784
INFO:root:QICETest: 0.08811
INFO:root:After validation: mem (CPU python)=3229.7109375MB; mem (CPU total)=71501.6875MB
