INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=540.94921875MB; mem (CPU total)=67713.4375MB
INFO:root:############### Starting experiment with config file debug_naval-propulsion-plant.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'energy', 'yarin_gal_uci_split_indices': 0, 'max_dataset_size': 1000, 'standardize': True}
INFO:root:After loading the datasets: mem (CPU python)=544.66796875MB; mem (CPU total)=67763.0390625MB
INFO:root:###1 out of 1 training parameter combinations ###
INFO:root:Training parameters: {'report_every': 5, 'seed': 1234, 'model': 'MLP', 'uncertainty_quantification': 'dropout', 'backbone': 'default', 'batch_size': 64, 'eval_batch_size': 16384, 'n_epochs': 1000, 'early_stopping': 50, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0.0, 'dropout': 0.1, 'hidden_dim': 64, 'n_layers': 2, 'distributional_method': 'mixednormal', 'concat_condition_diffusion': True, 'evaluate': True, 'x_T_sampling_method': 'CARD', 'conditional_free_guidance_training': True, 'regressor': None}
INFO:root:Using split-0 for UCI dataset energy
INFO:root:After creating the dataloaders: mem (CPU python)=545.421875MB; mem (CPU total)=67781.8984375MB
INFO:root:NumberParameters: 8961
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2155.44921875MB; mem (CPU total)=69794.69921875MB
INFO:root:Training starts now.
INFO:root:[    5] Training loss: 0.88488444, Validation loss: 0.75091201, Validation loss EMA: 0.75000322
INFO:root:[   10] Training loss: 0.61067278, Validation loss: 0.46344736, Validation loss EMA: 0.45066795
INFO:root:[   15] Training loss: 0.32440202, Validation loss: 0.21047574, Validation loss EMA: 0.19814290
INFO:root:[   20] Training loss: 0.15421586, Validation loss: 0.11247079, Validation loss EMA: 0.10312202
INFO:root:[   25] Training loss: 0.10287628, Validation loss: 0.09029523, Validation loss EMA: 0.07889560
INFO:root:[   30] Training loss: 0.08999643, Validation loss: 0.09115020, Validation loss EMA: 0.07361484
INFO:root:[   35] Training loss: 0.09078688, Validation loss: 0.08237783, Validation loss EMA: 0.07089088
INFO:root:[   40] Training loss: 0.08739998, Validation loss: 0.08928820, Validation loss EMA: 0.06909766
INFO:root:[   45] Training loss: 0.08470056, Validation loss: 0.08478507, Validation loss EMA: 0.06748751
INFO:root:[   50] Training loss: 0.08505515, Validation loss: 0.08119900, Validation loss EMA: 0.06623345
INFO:root:[   55] Training loss: 0.08171361, Validation loss: 0.07503288, Validation loss EMA: 0.06487346
INFO:root:[   60] Training loss: 0.08081204, Validation loss: 0.07525584, Validation loss EMA: 0.06334492
INFO:root:[   65] Training loss: 0.07986318, Validation loss: 0.07163236, Validation loss EMA: 0.06209231
INFO:root:[   70] Training loss: 0.07910566, Validation loss: 0.07409005, Validation loss EMA: 0.06081436
INFO:root:[   75] Training loss: 0.07700963, Validation loss: 0.07319155, Validation loss EMA: 0.05921242
INFO:root:[   80] Training loss: 0.07537844, Validation loss: 0.07399830, Validation loss EMA: 0.05763882
INFO:root:[   85] Training loss: 0.07517614, Validation loss: 0.06950134, Validation loss EMA: 0.05620608
INFO:root:[   90] Training loss: 0.07144005, Validation loss: 0.07147411, Validation loss EMA: 0.05450872
INFO:root:[   95] Training loss: 0.06988393, Validation loss: 0.06574574, Validation loss EMA: 0.05270325
INFO:root:[  100] Training loss: 0.06838767, Validation loss: 0.07066217, Validation loss EMA: 0.05106520
INFO:root:[  105] Training loss: 0.06837216, Validation loss: 0.06161976, Validation loss EMA: 0.04936955
INFO:root:[  110] Training loss: 0.06693610, Validation loss: 0.06578643, Validation loss EMA: 0.04802613
INFO:root:[  115] Training loss: 0.06506219, Validation loss: 0.05795707, Validation loss EMA: 0.04649795
INFO:root:[  120] Training loss: 0.06170757, Validation loss: 0.06155720, Validation loss EMA: 0.04510717
INFO:root:[  125] Training loss: 0.06256538, Validation loss: 0.05286792, Validation loss EMA: 0.04362592
INFO:root:[  130] Training loss: 0.06028552, Validation loss: 0.05680034, Validation loss EMA: 0.04242795
INFO:root:[  135] Training loss: 0.05873073, Validation loss: 0.05774643, Validation loss EMA: 0.04133146
INFO:root:[  140] Training loss: 0.05892599, Validation loss: 0.05492742, Validation loss EMA: 0.04019826
INFO:root:[  145] Training loss: 0.05690708, Validation loss: 0.05374075, Validation loss EMA: 0.03909626
INFO:root:[  150] Training loss: 0.05489769, Validation loss: 0.05240352, Validation loss EMA: 0.03776946
INFO:root:[  155] Training loss: 0.05708208, Validation loss: 0.05019497, Validation loss EMA: 0.03647839
INFO:root:[  160] Training loss: 0.05360045, Validation loss: 0.05348028, Validation loss EMA: 0.03529200
INFO:root:[  165] Training loss: 0.05301022, Validation loss: 0.05092930, Validation loss EMA: 0.03431344
INFO:root:[  170] Training loss: 0.05290921, Validation loss: 0.04503489, Validation loss EMA: 0.03294273
INFO:root:[  175] Training loss: 0.05266433, Validation loss: 0.04859618, Validation loss EMA: 0.03155490
INFO:root:[  180] Training loss: 0.04915658, Validation loss: 0.04973813, Validation loss EMA: 0.03086605
INFO:root:[  185] Training loss: 0.04769776, Validation loss: 0.04650076, Validation loss EMA: 0.03033613
INFO:root:[  190] Training loss: 0.04718095, Validation loss: 0.04738655, Validation loss EMA: 0.03001787
INFO:root:[  195] Training loss: 0.04689762, Validation loss: 0.04646332, Validation loss EMA: 0.02955254
INFO:root:[  200] Training loss: 0.04779505, Validation loss: 0.03989418, Validation loss EMA: 0.02897967
INFO:root:[  205] Training loss: 0.04520555, Validation loss: 0.04319577, Validation loss EMA: 0.02839662
INFO:root:[  210] Training loss: 0.04586791, Validation loss: 0.04118839, Validation loss EMA: 0.02778264
INFO:root:[  215] Training loss: 0.04499563, Validation loss: 0.04226765, Validation loss EMA: 0.02717846
INFO:root:[  220] Training loss: 0.04337603, Validation loss: 0.04354605, Validation loss EMA: 0.02652306
INFO:root:[  225] Training loss: 0.04223045, Validation loss: 0.04314365, Validation loss EMA: 0.02581599
INFO:root:[  230] Training loss: 0.04221697, Validation loss: 0.04315543, Validation loss EMA: 0.02513294
INFO:root:[  235] Training loss: 0.04278378, Validation loss: 0.03959804, Validation loss EMA: 0.02446211
INFO:root:[  240] Training loss: 0.04049667, Validation loss: 0.04004730, Validation loss EMA: 0.02379894
INFO:root:[  245] Training loss: 0.04068379, Validation loss: 0.03692811, Validation loss EMA: 0.02315984
INFO:root:[  250] Training loss: 0.03998432, Validation loss: 0.03867692, Validation loss EMA: 0.02256825
INFO:root:[  255] Training loss: 0.03886473, Validation loss: 0.03564496, Validation loss EMA: 0.02202715
INFO:root:[  260] Training loss: 0.03843215, Validation loss: 0.03841432, Validation loss EMA: 0.02147639
INFO:root:[  265] Training loss: 0.03730306, Validation loss: 0.03888541, Validation loss EMA: 0.02097241
INFO:root:[  270] Training loss: 0.03777519, Validation loss: 0.03901176, Validation loss EMA: 0.02045977
INFO:root:[  275] Training loss: 0.03585001, Validation loss: 0.03556464, Validation loss EMA: 0.01996013
INFO:root:[  280] Training loss: 0.03683130, Validation loss: 0.03328131, Validation loss EMA: 0.01948248
INFO:root:[  285] Training loss: 0.03729603, Validation loss: 0.03732080, Validation loss EMA: 0.01904205
INFO:root:[  290] Training loss: 0.03520078, Validation loss: 0.03643030, Validation loss EMA: 0.01861377
INFO:root:[  295] Training loss: 0.03521223, Validation loss: 0.03456448, Validation loss EMA: 0.01818559
INFO:root:[  300] Training loss: 0.03545840, Validation loss: 0.03460297, Validation loss EMA: 0.01778843
INFO:root:[  305] Training loss: 0.03462085, Validation loss: 0.03321269, Validation loss EMA: 0.01737747
INFO:root:[  310] Training loss: 0.03514753, Validation loss: 0.03148160, Validation loss EMA: 0.01701554
INFO:root:[  315] Training loss: 0.03196437, Validation loss: 0.03396253, Validation loss EMA: 0.01667231
INFO:root:[  320] Training loss: 0.03235187, Validation loss: 0.03267343, Validation loss EMA: 0.01632749
INFO:root:[  325] Training loss: 0.03280332, Validation loss: 0.03230288, Validation loss EMA: 0.01598524
INFO:root:[  330] Training loss: 0.03147896, Validation loss: 0.02708025, Validation loss EMA: 0.01564432
INFO:root:[  335] Training loss: 0.03129183, Validation loss: 0.02742170, Validation loss EMA: 0.01531887
INFO:root:[  340] Training loss: 0.03123939, Validation loss: 0.02736565, Validation loss EMA: 0.01497991
INFO:root:[  345] Training loss: 0.03082957, Validation loss: 0.02915905, Validation loss EMA: 0.01462056
INFO:root:[  350] Training loss: 0.03005713, Validation loss: 0.02894487, Validation loss EMA: 0.01427097
INFO:root:[  355] Training loss: 0.02820751, Validation loss: 0.02840993, Validation loss EMA: 0.01393591
INFO:root:[  360] Training loss: 0.02846647, Validation loss: 0.02837461, Validation loss EMA: 0.01358132
INFO:root:[  365] Training loss: 0.02950186, Validation loss: 0.03166055, Validation loss EMA: 0.01325568
INFO:root:[  370] Training loss: 0.02837889, Validation loss: 0.02990604, Validation loss EMA: 0.01288912
INFO:root:[  375] Training loss: 0.02905560, Validation loss: 0.02556610, Validation loss EMA: 0.01259041
INFO:root:[  380] Training loss: 0.02719089, Validation loss: 0.02422820, Validation loss EMA: 0.01226722
INFO:root:[  385] Training loss: 0.02798329, Validation loss: 0.02642948, Validation loss EMA: 0.01190556
INFO:root:[  390] Training loss: 0.02663708, Validation loss: 0.02557294, Validation loss EMA: 0.01154657
INFO:root:[  395] Training loss: 0.02636413, Validation loss: 0.02612915, Validation loss EMA: 0.01119864
INFO:root:[  400] Training loss: 0.02662892, Validation loss: 0.02521749, Validation loss EMA: 0.01085290
INFO:root:[  405] Training loss: 0.02405538, Validation loss: 0.02417634, Validation loss EMA: 0.01051410
INFO:root:[  410] Training loss: 0.02552325, Validation loss: 0.02441213, Validation loss EMA: 0.01017612
INFO:root:[  415] Training loss: 0.02454120, Validation loss: 0.02313425, Validation loss EMA: 0.00986646
INFO:root:[  420] Training loss: 0.02455651, Validation loss: 0.02414962, Validation loss EMA: 0.00955625
INFO:root:[  425] Training loss: 0.02399901, Validation loss: 0.02346100, Validation loss EMA: 0.00927779
INFO:root:[  430] Training loss: 0.02322976, Validation loss: 0.02430208, Validation loss EMA: 0.00897337
INFO:root:[  435] Training loss: 0.02229075, Validation loss: 0.02365244, Validation loss EMA: 0.00866451
INFO:root:[  440] Training loss: 0.02321703, Validation loss: 0.02352660, Validation loss EMA: 0.00838372
INFO:root:[  445] Training loss: 0.02233299, Validation loss: 0.01944376, Validation loss EMA: 0.00811091
INFO:root:[  450] Training loss: 0.02369725, Validation loss: 0.02329016, Validation loss EMA: 0.00786858
INFO:root:[  455] Training loss: 0.02243010, Validation loss: 0.02021754, Validation loss EMA: 0.00762179
INFO:root:[  460] Training loss: 0.02345447, Validation loss: 0.02382956, Validation loss EMA: 0.00739220
INFO:root:[  465] Training loss: 0.02118787, Validation loss: 0.02010874, Validation loss EMA: 0.00712164
INFO:root:[  470] Training loss: 0.02148855, Validation loss: 0.02135281, Validation loss EMA: 0.00689333
INFO:root:[  475] Training loss: 0.02045449, Validation loss: 0.02219914, Validation loss EMA: 0.00666642
INFO:root:[  480] Training loss: 0.02263757, Validation loss: 0.02034467, Validation loss EMA: 0.00644599
INFO:root:[  485] Training loss: 0.02117854, Validation loss: 0.01954232, Validation loss EMA: 0.00626474
INFO:root:[  490] Training loss: 0.01995982, Validation loss: 0.02033999, Validation loss EMA: 0.00607081
INFO:root:EP 494: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=3191.2265625MB; mem (CPU total)=64620.51171875MB
INFO:root:Training the model took 53.629s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model MLP & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.91807
INFO:root:RMSETrain: 0.95816
INFO:root:EnergyScoreTrain: 0.55336
INFO:root:CRPSTrain: 0.54706
INFO:root:Gaussian NLLTrain: 1.54251
INFO:root:CoverageTrain: 0.88857
INFO:root:QICETrain: 0.03233
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.91026
INFO:root:RMSEValidation: 0.95407
INFO:root:EnergyScoreValidation: 0.54541
INFO:root:CRPSValidation: 0.53907
INFO:root:Gaussian NLLValidation: 1.52691
INFO:root:CoverageValidation: 0.89626
INFO:root:QICEValidation: 0.03184
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 1.76649
INFO:root:RMSETest: 1.32909
INFO:root:EnergyScoreTest: 0.74215
INFO:root:CRPSTest: 0.73582
INFO:root:Gaussian NLLTest: 1.83991
INFO:root:CoverageTest: 0.80519
INFO:root:QICETest: 0.06805
INFO:root:After validation: mem (CPU python)=3204.4453125MB; mem (CPU total)=63319.08203125MB
